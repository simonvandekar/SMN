[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Methods for Neuroimaging",
    "section": "",
    "text": "Goal 1: Provide basic knowledge of neuroimaging so that you (Biostatisticians) can read and understand neuroimaging research.\nGoal 2: Cover modern contributions of biostatistics to neuroimaging methods so you can contribute to novel research in the field."
  },
  {
    "objectID": "index.html#course-goals",
    "href": "index.html#course-goals",
    "title": "Statistical Methods for Neuroimaging",
    "section": "",
    "text": "Goal 1: Provide basic knowledge of neuroimaging so that you (Biostatisticians) can read and understand neuroimaging research.\nGoal 2: Cover modern contributions of biostatistics to neuroimaging methods so you can contribute to novel research in the field.\nGoal 3: Hopefully, we can get you pretty close to doing novel research in statistical neuroimaging."
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Statistical Methods for Neuroimaging",
    "section": "Course Description",
    "text": "Course Description\nThis course covers standard and advanced methods for neuroimage analysis from a biostatistical perspective. Students will learn to analyze and interpret common modalities such as fMRI, structural MRI, cortical thickness, diffusion-weighted imaging, and resting-state connectivity using popular neuroimaging analysis software and visualization tools. Advanced topics may include site/scanner correction, first-level and group-level models, network analysis, AI/machine learning, circularity analysis, multivariate/spatial inference, confidence set methods, and centile methods. Upon completion, students will be prepared to understand and contribute to statistical research in neuroimaging."
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "Statistical Methods for Neuroimaging",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nGain a foundational understanding of key neuroimaging modalities and their applications in research.\nDevelop practical skills for preprocessing neuroimaging data using FSL.\nApply statistical analysis techniques to neuroimaging data, including first-level, group-level, and functional connectivity analyses.\nUnderstand/apply modern topics in neuroimaging data analysis such as site/scanner effects, circularity, multiple testing, machine learning, and Bayesian approaches."
  },
  {
    "objectID": "index.html#course-context",
    "href": "index.html#course-context",
    "title": "Statistical Methods for Neuroimaging",
    "section": "Course Context",
    "text": "Course Context\n\nWho are you (the student): Graduate students with a background in biostatistics or related fields.\nPrerequisites: Prior coursework in statistics or biostatistics and experience with R or Python (I will use R)."
  },
  {
    "objectID": "index.html#grading-tentative",
    "href": "index.html#grading-tentative",
    "title": "Statistical Methods for Neuroimaging",
    "section": "Grading (Tentative)",
    "text": "Grading (Tentative)\nYour grade will be determined from\n\nQuizzes (25%): These will be basic questions about terminology and course content. Grading is based on correct/incorrect answers.\nMini projects (50%): These will be smaller hands on projects to get you basic exposure to the data and analysis pipelines. We will use a rubric with instructor (me)/peer (you)/ChatGPT (AI) review. TBD.\nFinal project (25%): These will be a bigger hands on project to get you basic exposure to the data and analysis pipelines. Probably in groups. We will use a rubric with instructor (me)/peer (you)/ChatGPT (AI) review. TBD."
  },
  {
    "objectID": "index.html#potential-course-topics-tentative",
    "href": "index.html#potential-course-topics-tentative",
    "title": "Statistical Methods for Neuroimaging",
    "section": "Potential Course Topics (Tentative)",
    "text": "Potential Course Topics (Tentative)\n\nIntroduction\n\nIntroduction and setup\n\nCourse Introduction\nAccessing repository data, Data Use Agreements (DUA)\nInstalling FSL\n\n\n\n\nData Modalities\n\nIntroduction to Neuroimaging Modalities\n\nfMRI and rs-fMRI Overview\nDTI\nStructural Imaging\n\n\n\n\nPreprocessing and First-Level Analysis\n\nPreprocessing Pipeline\n\nStructural\nfMRI, rs-fMRI\n\nPreprocessing with FSL: Practical Session\nPreprocessing: Brainlife.io/Docker\nFirst-Level Statistical Analysis\n\nfMRI, rs-fMRI Analysis\n\nPractical implementation\n\n\n\nGroup-Level Analysis\n\nMultiplicity, Type 1 error, FWER, FDR\nCluster extent inference, Gaussian field theory, TFCE, Excursion set inference\nFunctional Connectivity: basic group-level analysis\nIn-class activity: implementation in FSL and R\n“Voodoo” correlation\nAdvanced group-level analysis (distance-based)\n\nMDMR, PermANOVA, Semi-parametrics\n\n\n\n\nModern Topics: Reproducibility and Replicability\n\nReproducibility\n\n“The Garden of Forking Paths”\n\nReplicability\n\nSample sizes\nEffect sizes\n\n\n\n\nModern Topics: Machine Learning in Neuroimaging\n\nBrain-behavior associations (e.g. “Multivariate BWAS”)\n\nPrediction\nStatistical inference\n\nReplicability in ML Methods\n\nCircularity, Data Leakage, and Feature Selection\nCross-validation, Bootstrapping\n\nGuest lecture from Megan?\nBrain Age\n\nIn-class activity\n\nOther topics\n\nMVPA\nML methods\nDeep learning\n\n\n\n\nModern Topics: Batch Effects\n\nIllustration with data so far\nComBat\nCovBat\nDeep learning\n\n\n\nModern Topics: Misc\n\nCentile Analysis\nMultimodal Image Analysis"
  },
  {
    "objectID": "index.html#course-schedule",
    "href": "index.html#course-schedule",
    "title": "Statistical Methods for Neuroimaging",
    "section": "Course Schedule",
    "text": "Course Schedule\n\n\nCode\nlibrary(knitr)\nlibrary(kableExtra)\n\n# Read the CSV file\nschedule = read.csv(\"courseSchedule.csv\", na.strings=\"NA\", check.names=FALSE)\n\n# Display nicely\n kable(schedule, caption = \"Neuroimaging Course Schedule\", align = \"l\", escape=FALSE)\n\n\n\nNeuroimaging Course Schedule\n\n\nDate\nDay\nSection\nTopic\nIn class interactive\nAssignment\nDue date\n\n\n\n\n20-Aug\nWednesday\nIntroduction\nIntroduction and Setup\nSoftware debug\nQuiz & install software\n27-Aug\n\n\n25-Aug\nMonday\nData Modalities\nIntroduction to Neuroimaging Modalities\n\n\n\n\n\n27-Aug\nWednesday\nPreprocessing\nPreprocessing Pipeline\nRegistration with FSL\nQuiz\n12-Sep\n\n\n1-Sep\nMonday\n\nNo class: Labor day\n\n\n\n\n\n3-Sep\nWednesday\nPreprocessing\nStructural preprocessing\n\n\n\n\n\n8-Sep\nMonday\nPreprocessing\nRecorded: Structural and functional preprocessing\n\nDespicable Me preprocessing\n21-Sep\n\n\n10-Sep\nWednesday\n\nRecorded: Functional preprocessing\nDespicable Me preprocessing\n\n\n\n\n15-Sep\nMonday\nFirst-Level Analysis\nFirst-Level Statistical Analysis\n\n\n\n\n\n17-Sep\nWednesday\nFirst-Level Analysis\nFirst-Level Statistical Analysis with FSL\nDespicable Me first-level analysis\nFirst-level fMRI analysis of Despicable Me data\n\n\n\n22-Sep\nMonday\nFirst-Level Analysis\nrs-fMRI First-Level Statistical Analysis with FSL\nResting-state data preprocessing\n\n\n\n\n24-Sep\nWednesday\nGroup-Level Analysis\nEstimation\n\n\n\n\n\n29-Sep\nMonday\nGroup-Level Analysis\nMultiplicity, Type 1 error, FWER, FDR\n\n\n\n\n\n1-Oct\nWednesday\nGroup-Level Analysis\nCluster extent inference, Gaussian field theory, TFCE, Excursion set inference\n\n\n\n\n\n6-Oct\nMonday\nGroup-Level Analysis\n\nGroup-level analysis of Despicable Me\nGroup-level analysis of Despicable Me\n\n\n\n8-Oct\nWednesday\nGroup-Level Analysis\nFunctional Connectivity group-level analysis, implementation in FSL and R\n\n\n\n\n\n13-Oct\nMonday\nCommon Mistakes and Ongoing Challenges\n“Voodoo” correlation, circularity errors, data leakage\n\n\n\n\n\n15-Oct\nWednesday\nModern Topics\nOverview of modern topics and potential final projects\n\n\n\n\n\n20-Oct\nMonday\nModern Topics: Batch Effects\n\n\n\n\n\n\n22-Oct\nWednesday\nModern Topics: Machine Learning in Neuroimaging\n\n\n\n\n\n\n27-Oct\nMonday\nModern Topics: Reproducibility and Replicability\n\n\n\n\n\n\n29-Oct\nWednesday\nModern Topics: Misc\n\n\n\n\n\n\n3-Nov\nMonday\n\n\n\n\n\n\n\n5-Nov\nWednesday\n\n\n\nMachine learning Despicable Me\n\n\n\n10-Nov\nMonday\n\n\n\n\n\n\n\n12-Nov\nWednesday\n\n\n\n\n\n\n\n17-Nov\nMonday\n\n\n\n\n\n\n\n19-Nov\nWednesday\n\n\n\nFinal project reviews\n\n\n\n24-Nov\nMonday\n\nNo class: Thanksgiving break\n\n\n\n\n\n26-Nov\nWednesday\n\nNo class: Thanksgiving break\n\n\n\n\n\n1-Dec\nMonday\n\nFinal project presentations\n\n\n\n\n\n3-Dec\nWednesday\n\nFinal project presentations"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html",
    "href": "3first-level_analysis/first-level_analysis.html",
    "title": "First-level Analysis",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo = TRUE, eval=FALSE)"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#temporal-filtering",
    "href": "3first-level_analysis/first-level_analysis.html#temporal-filtering",
    "title": "First-level Analysis",
    "section": "Temporal filtering",
    "text": "Temporal filtering"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#convolution",
    "href": "3first-level_analysis/first-level_analysis.html#convolution",
    "title": "First-level Analysis",
    "section": "Convolution",
    "text": "Convolution"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#temporal-derivative",
    "href": "3first-level_analysis/first-level_analysis.html#temporal-derivative",
    "title": "First-level Analysis",
    "section": "Temporal derivative",
    "text": "Temporal derivative"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#temporal-filtering-1",
    "href": "3first-level_analysis/first-level_analysis.html#temporal-filtering-1",
    "title": "First-level Analysis",
    "section": "Temporal filtering",
    "text": "Temporal filtering"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#time-series",
    "href": "3first-level_analysis/first-level_analysis.html#time-series",
    "title": "First-level Analysis",
    "section": "Time series",
    "text": "Time series\n\ndm = readRDS('../data/RBC/stimulusTimeSeries/despicableMe/emotionBlocks.rds')\nplot(dm$emo_valence, type='p', ylab='Emotional Valence', xlab='Time', main='\"Despicable Me\" emotional ratings',\n     col=as.numeric(dm$positiveBlock) + as.numeric(dm$negativeBlock) -1)\n\n\n\nTo input the stimulus time series into FSL, we provide a 3 column text file with the following info\n\nOnset, Duration, Value\n\nInclude temporal derivative.\n\n\n# path to fsf file for preprocessing for first participant\n# /Users/vandeks/Library/CloudStorage/Box-Box/SMN/data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/func/sub-NDARAA306NT2_ses-HBNsiteRU_task-movieDM_bold.feat/design.fsf\npos = rle(dm$positive)\npos$lengths[1] = pos$lengths[1] - 6\n# first one starts at zero\npos$starts = c(0, cumsum(pos$lengths)[-length(pos$lengths)]+1)\n# output needed by FSL\nthreeCol = data.frame(onset=pos$starts, duration=pos$lengths, value=pos$values)\nwrite.table(threeCol[threeCol$value==1,], row.name=FALSE, sep=' ', col.names = FALSE, file='../data/RBC/stimulusTimeSeries/despicableMe/positiveStimulus.txt')\n# /Users/vandeks/Library/CloudStorage/Box-Box/SMN/data//RBC/stimulusTimeSeries/despicableMe/positiveStimulus.txt"
  },
  {
    "objectID": "2preprocessing/preprocessing.html",
    "href": "2preprocessing/preprocessing.html",
    "title": "Preprocessing",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo = TRUE, eval=FALSE)"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#general",
    "href": "2preprocessing/preprocessing.html#general",
    "title": "Preprocessing",
    "section": "General",
    "text": "General\n\nInhomogeneity correction\nBrain extraction\nRegistration (also called [spatial] normalization)\nSpatial smoothing (applied downstream prior to analysis)"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#structural",
    "href": "2preprocessing/preprocessing.html#structural",
    "title": "Preprocessing",
    "section": "Structural",
    "text": "Structural\n\nfsleyes images/MNI152_T1_1mm_brain.nii.gz images/simon.nii.gz\n\n\nInhomogeneity correction\nBrain extraction\nRegistration\nTissue segmentation\nVolume estimation\nSurface reconstruction and cortical thickness estimation\nSpatial smoothing"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#functional",
    "href": "2preprocessing/preprocessing.html#functional",
    "title": "Preprocessing",
    "section": "Functional",
    "text": "Functional\n\nInhomogeneity correction\nBrain extraction (via structural image)\nRegistration\nMotion correction\nSlice timing correction\nDistortion correction (if field map available)\nTemporal filtering & confound regression\nSpatial smoothing"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#inhomogeneity-correction-and-brain-extraction",
    "href": "2preprocessing/preprocessing.html#inhomogeneity-correction-and-brain-extraction",
    "title": "Preprocessing",
    "section": "Inhomogeneity correction and brain extraction",
    "text": "Inhomogeneity correction and brain extraction\n\nI won’t go into detail here, but know that these are preprocessing steps\nInhomogeneity correction adjusts for systematic differences in the brightness of the image\nBrain extraction removes the skull, eyes, and surrounding tissue\n\n\n# brain extracted generated by FSL's bet command\nfsleyes images/simon.nii.gz images images/simonReg/simon_brain.nii.gz"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#goal",
    "href": "2preprocessing/preprocessing.html#goal",
    "title": "Preprocessing",
    "section": "Goal",
    "text": "Goal\n\nBrains are structurally very different\nBrains as functions/images can have different coordinate systems\nTo compare features such as function or anatomy it helps if the coordinates are comparable\nMaking coordinates comparable is the goal of registration"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#terminology",
    "href": "2preprocessing/preprocessing.html#terminology",
    "title": "Preprocessing",
    "section": "Terminology",
    "text": "Terminology\n\nfsleyes images/MNI152_T1_1mm_brain.nii.gz images/simon.nii.gz\n\n\nInput/moving image I(w), w \\in \\mathbb{R}^3\nReference/target/template image R(v), v \\in \\mathbb{R}^3\nWe want to find a transformation T such that\n\n\nI(T(v)) \\approx R(v)"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#general-theory",
    "href": "2preprocessing/preprocessing.html#general-theory",
    "title": "Preprocessing",
    "section": "General theory",
    "text": "General theory\n\nEstimation: minimizes cost (or maximizes similarity)\nSimilarity metrics/cost functions\n\nLeast squares (images have the same scale) \nC\\{ R(v), I(T(v))\\} = \\int_{v \\subset \\mathbb{R}^3} \\{ I(T(v)) - R(v)\\}^2 dv\n\nCorrelation (images on different scales)\nMutual information (images with different contrasts/distributions) \n\\mathrm{MI}(R, I) = \\sum_{r,i} \\mathbb{P}_{RI}(r, i) \\log \\left( \\frac{\\mathbb{P}_{RI}(r, i)}{\\mathbb{P}_R(r), \\mathbb{P}_I(i)} \\right)\n\nwhere \\mathbb{P}_{RI}(r, i): is the joint probability, and \\mathbb{P}_R(r), \\mathbb{P}_I(i) are the marginal probabilities\n\nTransformation computed to minimize \n\\min_T C\\{R(v), I(T(v))\\}\n\nSome of these cost functions are convex given some assumptions on the images\nThat would imply a global optimum, given some assumtions on I and R\nThose assumptions are not met, so many adhoc approaches are implemented1\nPenalty terms are often useful\nRegistration is a challenging problem\n\n“In theory, there is no difference between theory and practice. In practice, there is.”"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#rigid-body",
    "href": "2preprocessing/preprocessing.html#rigid-body",
    "title": "Preprocessing",
    "section": "Rigid-body",
    "text": "Rigid-body\n\nSix parameter rigid registration\nUsed to align functional images over time (motion correction)\nAlso used to align images from the same participant collect in the same scan session.\ny = (y_1, y_2, y_3, 1) - template coordinates, x = (x_1, x_2, x_3, 1) input coordinates\nAppended with an intercept for transformation\nCan be described as the composition of four transformations\n\n\n\\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\ny_3\\\\\n1\n\\end{bmatrix}\n= T_4 T_3 T_2  T_1 \\cdot\n\\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3\\\\\n1\n\\end{bmatrix}\n\nTranslation of image \nT_4 = \\begin{bmatrix}\n1 & 0 & 0 & q_1 \\\\\n0 & 1 & 0 & q_2 \\\\\n0 & 0 & 1 & q_3\\\\\n0 & 0 & 0 & 1\n\\end{bmatrix}\n\nRotation around the x-axis:\n\nT_1 = \\begin{bmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & \\cos(q_4) & \\sin(q_4) & 0 \\\\\n0 & -\\sin(q_4) & \\cos(q_4) & 0\\\\\n0 & 0 & 0 & 1\n\\end{bmatrix}\n\nOther rotations are defined similarly. See the reference above."
  },
  {
    "objectID": "2preprocessing/preprocessing.html#affine-linear-registration",
    "href": "2preprocessing/preprocessing.html#affine-linear-registration",
    "title": "Preprocessing",
    "section": "Affine (linear) registration",
    "text": "Affine (linear) registration\n\nLinear (Affine, actually) registration is 12 parameters\nThe rigid body transformations are further augmented with “zoom” and “shear”\nAll registrations should be invertible so that the reference can be moved to the space of the input"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#example-of-registration-results",
    "href": "2preprocessing/preprocessing.html#example-of-registration-results",
    "title": "Preprocessing",
    "section": "Example of registration results",
    "text": "Example of registration results\nCommands I ran:\n\nfast -B images/simon_bc.nii.gz images/simon.nii.gz\nbet images/simon_bc.nii.gz images/simonReg/simon_brain.nii.gz\n# dof controls number of parameters 6 is rigid-body\nflirt -in images/simonReg/simon_brain.nii.gz -ref images/MNI152_T1_1mm_brain.nii.gz -dof 6 -o images/simonReg/simon_brain_rigidReg.nii.gz -omat images/simonReg/rigidReg.txt\n# defaults to 12 for affine transformation\nflirt -in images/simonReg/simon_brain.nii.gz -ref images/MNI152_T1_1mm_brain.nii.gz -o images/simonReg/simon_brain_affineReg.nii.gz -omat images/simonReg/affineReg.txt\n\nTo view the results with the MNI template\n\nfsleyes images/MNI152_T1_1mm_brain.nii.gz images/simonReg/simon_brain.nii.gz images/simonReg/simon_brain_rigidReg.nii.gz images/simonReg/simon_brain_affineReg.nii.gz\n\nTo view transformation matrices\n\ncat images/simonReg/rigidReg.txt\ncat images/simonReg/affineReg.txt\n\n\nBrain extraction\nRigid-body\nAffine"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#interpolation",
    "href": "2preprocessing/preprocessing.html#interpolation",
    "title": "Preprocessing",
    "section": "Interpolation",
    "text": "Interpolation\n\nImages are measured on a grid, so applying the transformation T may require evaluation of the image, I, at locations not represented by a grid coordinate\nInterpolation computes I(T(v)) at non-grid locations\nRequired for evaluating cost function and when applying the resulting transformation matrix.\nInterpolation methods\nNearest neighbor interpolation is important when registering atlas images\n\nAtlas images are integer valued and nearest neighbor ensures output is integer valued"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#nonlinear-deformable-registration",
    "href": "2preprocessing/preprocessing.html#nonlinear-deformable-registration",
    "title": "Preprocessing",
    "section": "Nonlinear (deformable) registration",
    "text": "Nonlinear (deformable) registration\n\nDeformable registration allows different parts of the image to have a unique transformation matrix\nCalled a deformation field \\phi(x) such that y = \\phi(x).\nDifferent approaches:\n\nB‑splines, diffeomorphisms (e.g., LDDMM, SyN), demons, finite-element\n\nEnforces smoothness, invertibility, and topology preservation via regularization.\nTypically linear transformation is estimated first, then function composition is used when estimating and evaluating the nonlinear transformation\nComposition avoids repeated interpolation of the image\nANTs registration paper Avants et al (2009).\n\n\nfnirt --ref=images/MNI152_T1_1mm_brain.nii.gz --in=images/simonReg/simon_brain.nii.gz --aff=images/simonReg/affineReg.txt --fout=images/simonReg/field.nii.gz --jout=images/simonReg/jacobian.nii.gz --iout=images/simonReg/simon_nonlinearReg.nii.gz --cout=images/simonReg/simon2MNI.nii.gz \n\nVisualize results\n\nfsleyes images/MNI152_T1_1mm_brain.nii.gz images/simonReg/simon_brain_affineReg.nii.gz images/simonReg/simon_nonlinearReg.nii.gz"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#registration-to-a-template",
    "href": "2preprocessing/preprocessing.html#registration-to-a-template",
    "title": "Preprocessing",
    "section": "Registration to a template",
    "text": "Registration to a template\n\nCommon template images\n\nMNI template – MNI template is most common target for registration\nStudy-specific template – in unique populations, often better to create a study-specific template\n\ne.g. Pediatric, aging, or patient populations"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#registration-output",
    "href": "2preprocessing/preprocessing.html#registration-output",
    "title": "Preprocessing",
    "section": "Registration output",
    "text": "Registration output\n\nls ../images/simonReg\n\nMNI2simon.nii.gz\naffineReg.txt\nfield.nii.gz\njacobian.nii.gz\nrigidReg.txt\nsimon2MNI.nii.gz\nsimon_bet.nii.gz\nsimon_brain.nii.gz\nsimon_brain_affineReg.nii.gz\nsimon_brain_mixeltype.nii.gz\nsimon_brain_pve_0.nii.gz\nsimon_brain_pve_1.nii.gz\nsimon_brain_pve_2.nii.gz\nsimon_brain_pveseg.nii.gz\nsimon_brain_rigidReg.nii.gz\nsimon_brain_seg.nii.gz\nsimon_brain_to_MNI152_T1_1mm_brain.log\nsimon_brain_warpcoef.nii.gz\nsimon_nonlinearReg.nii.gz\n\n\n\nWarp field – Tells the registration algorithm how much and what direction to move each voxel value\nJacobian of the transformation – More accurately, the Jacobian determinant.\n\nThe Jacobian is the (matrix valued) derivative of the warp field at each location. It describes how the voxel coordinates get moved at a given location\nThe determinant of the transformation describes the amount the voxel has to move"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#advanced-registration-topics",
    "href": "2preprocessing/preprocessing.html#advanced-registration-topics",
    "title": "Preprocessing",
    "section": "Advanced registration topics",
    "text": "Advanced registration topics\n\nStudy specific templates\n\nPopulations vary and a standard template might not be appropriate\nExamples: Kids or older adults\nAverages can be defined geometrically and modeled by covariates, which seems cool"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#references",
    "href": "2preprocessing/preprocessing.html#references",
    "title": "Preprocessing",
    "section": "References",
    "text": "References\n\nHuman brain function online book (from the authors of SPM software\nChapter 2 from HBF book"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#goal-1",
    "href": "2preprocessing/preprocessing.html#goal-1",
    "title": "Preprocessing",
    "section": "Goal",
    "text": "Goal\n\nRegistration is imperfect, applying spatial smoothing reduces between subject variability\nIf there is voxel-level independent Gaussian noise, spatial smoothing will reduce the noise – math for this is relatively easy\nSmoothing is typically applied to images before statistical analysis\nValue at a smoothed voxel is a Gaussian weighted average of surrounding voxels in unsmoothed image"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#terminology-1",
    "href": "2preprocessing/preprocessing.html#terminology-1",
    "title": "Preprocessing",
    "section": "Terminology",
    "text": "Terminology\n\nFWHM - full width at half maximum, typically in mm. Description of size of Gaussian kernel for smooth\nSigma - \\sigma = \\frac{\\mathrm{FWHM}}{2\\sqrt{2\\log(2)}}\n\n\nSmoothing kernels CPAC pipeline"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#c-pac-anatomical-pipeline",
    "href": "2preprocessing/preprocessing.html#c-pac-anatomical-pipeline",
    "title": "Preprocessing",
    "section": "C-PAC anatomical pipeline",
    "text": "C-PAC anatomical pipeline\n\nAnatomical pipelineOption/Alt + click to zoom in."
  },
  {
    "objectID": "2preprocessing/preprocessing.html#segmentation",
    "href": "2preprocessing/preprocessing.html#segmentation",
    "title": "Preprocessing",
    "section": "Segmentation",
    "text": "Segmentation\n\nSegmentation estimates gray/white matter, CSF/ventricles\nVariations on mixture models that incorporate priors and spatial dependence\n\n\n# output from fsl_anat.\n# Base image is the input data.\n# Second image is the segmentation output\nfsleyes data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/sub-NDARAA306NT2_ses-HBNsiteRU_acq-HCP_T1w.anat/T1.nii.gz data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/sub-NDARAA306NT2_ses-HBNsiteRU_acq-HCP_T1w.anat/T1_fast_pveseg.nii.gz"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#volume-estimation",
    "href": "2preprocessing/preprocessing.html#volume-estimation",
    "title": "Preprocessing",
    "section": "Volume estimation",
    "text": "Volume estimation\nEstimation of volumes of regions defined from an anatomical atlas.\nApproaches:\n\nRegistration - invert warp to map atlas to subject space\nMulti-atlas label fusion - Registration-based. Information from multiple manually labeled atlases can improve estimation\nJoint label fusion\nProbabilistic atlases/Bayesian models\nWe can discuss these more as an advanced topic if there is interest"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#volume-estimation-example",
    "href": "2preprocessing/preprocessing.html#volume-estimation-example",
    "title": "Preprocessing",
    "section": "Volume estimation example",
    "text": "Volume estimation example\n\n# invert the warp from subject space to template space\ninvwarp -w images/simonReg/simon2MNI.nii.gz -o images/simonReg/MNI2simon.nii.gz -r images/simonReg/simon_brain.nii.gz\n# convert atlas to subject space. Use nearest neighbor interpolation\napplywarp --i=/Users/vandeks/fsl/data/atlases/HarvardOxford/HarvardOxford-cort-maxprob-thr25-1mm.nii.gz --ref=images/simonReg/simon_brain.nii.gz --warp=images/simonReg/MNI2simon.nii.gz --out=images/simonReg/HO_simon.nii.gz --interp=nn\n# visualize results on simon's brain\nfsleyes images/simonReg/simon_brain.nii.gz images/simonReg/HO_simon.nii.gz\n\nCode from ChatGPT to compute volumes.\n\n# 2. Estimate voxel volume (assumes cubic mm)\nvoxel_volume=$(fslval ${ref_image} pixdim1)\nvoxel_volume=$(echo \"${voxel_volume} * $(fslval ${ref_image} pixdim2) * $(fslval ${ref_image} pixdim3)\" | bc -l)\n\n# 3. Loop over atlas labels to count voxels and estimate volume\necho \"Label,VoxelCount,Volume_mm3\"\nfor label in {1..48}; do\n  count=$(fslstats ${atlas_subj} -l $(($label - 1)) -u $label -V | awk '{print $1}')\n  volume=$(echo \"$count * $voxel_volume\" | bc -l)\n  echo \"$label,$count,$volume\"\ndone"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#derivatives-of-the-registration-process",
    "href": "2preprocessing/preprocessing.html#derivatives-of-the-registration-process",
    "title": "Preprocessing",
    "section": "Derivatives of the registration process",
    "text": "Derivatives of the registration process\n\nFeatures of the registration process are informative of brain structure\nProbabilistic tissue segmentation: images can be analyzed across participants after registration to template space\nDeterminant of the Jacobian: quantifies how much the image needed to be warped at that location to fit into the template space\nVoxel-based morphometry (VBM) combines Jacobian and tissue segmentation images to compare gray matter volume in template space\n\nMechelli 2005 – Review of VBM\nAntonopoulos 2023 – Recent comparison of VBM methods"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#cortical-surface-reconstruction",
    "href": "2preprocessing/preprocessing.html#cortical-surface-reconstruction",
    "title": "Preprocessing",
    "section": "Cortical surface reconstruction",
    "text": "Cortical surface reconstruction\nFreesurfer is among the most popular software for cortical surface reconstruction\n\nAllows projection of other data (e.g. fMRI) to the surface\nAll analyses can be performed on the surface\nRegistration in Freesurfer occurs on the surface manifold instead of in 3D\n\nRespects biology of the brain\n\nSmoothing is done on the surface – avoids smoothing over sulci\nCon: Does not include subcortex\n\n\n\n\n\n\nIrimia et al. 2012\n\n\n\n\n\n\nInflated surface"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#freesurfer-software-output",
    "href": "2preprocessing/preprocessing.html#freesurfer-software-output",
    "title": "Preprocessing",
    "section": "Freesurfer software output",
    "text": "Freesurfer software output\n\nrecon-all -subjid subjid -i inputFile.nii.gz -all\n\n\nFully automated call, though it is not without errors/flaws\nA look at the Freesurfer output – maybe later"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#what-are-fmri-data",
    "href": "2preprocessing/preprocessing.html#what-are-fmri-data",
    "title": "Preprocessing",
    "section": "What are fMRI data?",
    "text": "What are fMRI data?\n\nfMRI measures brain activity over time by detecting changes in blood oxygenation.\nfMRI data are a time series of 3D brain images, collected every 1–3 seconds (TR = repetition time).\nEach voxel (3D pixel) contains a time series reflecting fluctuations in signal intensity across the scan.\nThe signal includes BOLD (Blood Oxygenation Level-Dependent) response\n\nBased on the fact that oxygenated and deoxygenated hemoglobin have different magnetic properties.\nNeural activity, increased blood flow, local increase in oxygenated blood, measurable signal change.\n\nData are collected while participants\n\nPerform a task (task-based fMRI)\nRest with eyes open/closed (resting-state fMRI)\n\nfMRI is indirect: it measures blood flow, not neural activity itself."
  },
  {
    "objectID": "2preprocessing/preprocessing.html#functional-preprocessing-pipeline",
    "href": "2preprocessing/preprocessing.html#functional-preprocessing-pipeline",
    "title": "Preprocessing",
    "section": "Functional preprocessing pipeline",
    "text": "Functional preprocessing pipeline\n\nScientists have developed many software tools for preprocessing\nThe analysis pipeline is very sophisticated\nTeams have developed pipeline tools that make it easier to reproducibly preprocess the data\n\nExample CPAC functional pipeline\n\n\n\nFunctional pipeline"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#slice-timing-correction",
    "href": "2preprocessing/preprocessing.html#slice-timing-correction",
    "title": "Preprocessing",
    "section": "Slice Timing Correction",
    "text": "Slice Timing Correction\n\nfMRI data are collected sequentially in 2-d slices in the z-plane\n\nOver the course of one TR (repetition time; approximately 2 seconds [0.5-3 seconds] ), the time the first slice and the last slice are acquired is the TR length\n\nSlice timing adjusts voxel intensities in each slice to a common acquisition reference (e.g., the first slice)\n\nCorrects timing offsets across the TR to align the hemodynamic response\n\nUses interpolation (e.g., sinc, Fourier) based on slice order (alt‑z, seq, etc.)\nMultiband fMRI methods can acquire several slices simultaneously, reducing the TR.\n\nSlice timing GIF in Andy’s Brain Book"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#motion-correction",
    "href": "2preprocessing/preprocessing.html#motion-correction",
    "title": "Preprocessing",
    "section": "Motion correction",
    "text": "Motion correction\n\nThe participant will move across the scan time\nMotion correction in FSL\n\nAlign volumes to mean image\n\nMotion correction in AFNI (another software)\n\nAlign volumes to mean image\nRealign again to newly computed mean for improved accuracy\n\n\n\nfsleyes data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/func/sub-NDARAA306NT2_ses-HBNsiteRU_task-movieDM_bold.nii.gz"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#motion-correction-output",
    "href": "2preprocessing/preprocessing.html#motion-correction-output",
    "title": "Preprocessing",
    "section": "Motion correction output",
    "text": "Motion correction output\n\nOutputs:\n\n6 motion parameters\nMean framewise displacement (FD) and motion plots\n\n\nMotion parameter time series are used as covariates in first-level analysis\n\n\nMotion parameters from Despicable Me"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#field-map-distortion-correction",
    "href": "2preprocessing/preprocessing.html#field-map-distortion-correction",
    "title": "Preprocessing",
    "section": "Field Map / Distortion Correction",
    "text": "Field Map / Distortion Correction\n\nCorrection of EPI geometric distortions due to inhomogeneity in the magnetic field\nSupported if you collected a fieldmap image\n\nApplies warp to fMRI, improving alignment to anatomy and standard space\nWe will skip this in our preprocessing\nAlso called B0 field unwarping\nMore details from FSL"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#functional-to-anatomical-registration",
    "href": "2preprocessing/preprocessing.html#functional-to-anatomical-registration",
    "title": "Preprocessing",
    "section": "Functional to Anatomical Registration",
    "text": "Functional to Anatomical Registration\n\nUses “boundary-based registration” for EPI-to-T1 alignment\n\nOutputs the transform matrix for resampling EPI into subject/anatomical space\n\n\nFunctional registration"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#brain-extraction",
    "href": "2preprocessing/preprocessing.html#brain-extraction",
    "title": "Preprocessing",
    "section": "Brain Extraction",
    "text": "Brain Extraction\n\nRemoves skull/face from fMRI data\nFSL’s BET tool fails for this participant\nVisualization below\nI created another one using fsl_anat tool (recommend this) and also using a manual registration-based approach\n\n\n# brain extraction fails here\nfast data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/sub-NDARAA306NT2_ses-HBNsiteRU_acq-HCP_T1w_bc.nii.gz\nbet data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/sub-NDARAA306NT2_ses-HBNsiteRU_acq-HCP_T1w_bc.nii.gz data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/sub-NDARAA306NT2_ses-HBNsiteRU_acq-HCP_T1w_bet.nii.gz\nfsleyes data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/sub-NDARAA306NT2_ses-HBNsiteRU_acq-HCP_T1w_bet.nii.gz"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#fsl-gui",
    "href": "2preprocessing/preprocessing.html#fsl-gui",
    "title": "Preprocessing",
    "section": "FSL GUI",
    "text": "FSL GUI\n\nFSL has a GUI (FEAT) for preprocessing Feat_gui\nInput:\n\nBrain extracted anatomical T1 image. (Also with skull)\nfMRI 4D Nifti time series image\nOptional B0 field map\nParameter settings\n\nBrain extraction for this participant failed. As a solution, I created a brain extracted anatomical image with the following commands\n\n\n# create mask with no holes\nfslmaths /Users/vandeks/fsl/data/standard/MNI152_T1_1mm_brain_mask.nii.gz -fillh /Users/vandeks/fsl/data/standard/MNI152_T1_1mm_brain_noholes_mask.nii.gz\n\n# Input images\nfunc=\"data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/func/sub-NDARAA306NT2_ses-HBNsiteRU_task-movieDM_bold.nii.gz\"\nanat=\"data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/sub-NDARAA306NT2_ses-HBNsiteRU_acq-HCP_T1w.nii.gz\"\n\n\n# register to the template\nflirt -in $anat -ref /Users/vandeks/fsl/data/standard/MNI152_T1_1mm.nii.gz -dof 12 -omat data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/linearReg.txt\n# get inverse transform\nconvert_xfm -inverse -omat data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/inv_linearReg.txt data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/linearReg.txt\n# Move MNI mask into subject space\nflirt -in /Users/vandeks/fsl/data/standard/MNI152_T1_1mm_brain_noholes_mask.nii.gz -ref $anat -applyxfm -init data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/inv_linearReg.txt -interp nearestneighbour -out data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/sub-NDARAA306NT2_ses-HBNsiteRU_acq-HCP_T1w_brain_mask.nii.gz\n# view the MNI mask in subject space\n# fsleyes data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/sub-NDARAA306NT2_ses-HBNsiteRU_acq-HCP_T1w.nii.gz data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/sub-NDARAA306NT2_ses-HBNsiteRU_acq-HCP_T1w_brain_mask.nii.gz\n# create brain only image by applying brain mask\nfslmaths data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/sub-NDARAA306NT2_ses-HBNsiteRU_acq-HCP_T1w.nii.gz -mas data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/sub-NDARAA306NT2_ses-HBNsiteRU_acq-HCP_T1w_brain_mask.nii.gz data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/anat/sub-NDARAA306NT2_ses-HBNsiteRU_acq-HCP_T1w_brain.nii.gz"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#fsl-preprocessing-summary",
    "href": "2preprocessing/preprocessing.html#fsl-preprocessing-summary",
    "title": "Preprocessing",
    "section": "FSL preprocessing summary",
    "text": "FSL preprocessing summary\n\nchrome data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/func/sub-NDARAA306NT2_ses-HBNsiteRU_task-movieDM_bold.feat/report_prestats.html\nchrome data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/func/sub-NDARAA306NT2_ses-HBNsiteRU_task-movieDM_bold.feat/report_reg.html"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#concluding-notes",
    "href": "2preprocessing/preprocessing.html#concluding-notes",
    "title": "Preprocessing",
    "section": "Concluding Notes",
    "text": "Concluding Notes\n\nPreprocessing is a complex component of image analysis\nLots of tools in FSL that are well accepted in the field\nPreprocessing pipelines like C-PAC are developed to choose the best/preferred software for each step\nC‑PAC is highly configurable/adaptable\nAlways check QA after each step for alignment and residual motion\nCheck out the homework assigment for preprocessing"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#footnotes",
    "href": "2preprocessing/preprocessing.html#footnotes",
    "title": "Preprocessing",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSoftware lists are non-exhaustive and based on my personal exposure.↩︎\n“In theory, there is no difference between theory and practice. In practice, there is.”↩︎"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html",
    "href": "1introduction_data_modalities/introduction_data_modalities.html",
    "title": "Introduction & Data Modalities",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#reproducible-brain-charts",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#reproducible-brain-charts",
    "title": "Introduction & Data Modalities",
    "section": "Reproducible Brain Charts",
    "text": "Reproducible Brain Charts\nReproducible Brain Charts\n\nWe will use structural, resting state functional MRI (rs-fMRI), and “task” fMRI (t-fMRI)"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#abcd-study",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#abcd-study",
    "title": "Introduction & Data Modalities",
    "section": "ABCD Study",
    "text": "ABCD Study\n\nAdolescent Brain Cognitive Development (ABCD)\nAmazing resource for large-scale imaging\nHuge study, requires complex data use agreement"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#analysis-software",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#analysis-software",
    "title": "Introduction & Data Modalities",
    "section": "Analysis software",
    "text": "Analysis software\n\nStatistical Parametric Mapping (SPM; in MATLAB)\nFSL (linux/terminal based) – Primary software for this course\nAFNI\nNeuroconductor – modular analysis packages in R"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#getting-setup-with-fsl",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#getting-setup-with-fsl",
    "title": "Introduction & Data Modalities",
    "section": "Getting setup with FSL",
    "text": "Getting setup with FSL\n\necho $FSLDIR\n\n\nVisualize the FSL template image\nVisualize my brain"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#visualization-software",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#visualization-software",
    "title": "Introduction & Data Modalities",
    "section": "Visualization software",
    "text": "Visualization software\nVisualization is as important in image analysis as univariate data analysis (Always look at your data)\n\nFSLeyes\nITK-Snap\nPapaya\nR packages, ggseg, ciftitools, fsbrain, see following reference\nChopra et al., 2023 – overview of reproducible tools"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#anatomy-and-terminology",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#anatomy-and-terminology",
    "title": "Introduction & Data Modalities",
    "section": "Anatomy and terminology",
    "text": "Anatomy and terminology\n\n1introduction_data_modalities/figures/simon.nii.gz\n\nDirectory paths will be relative to the course directory on Box.\n\nGray Matter: Brain tissue composed mainly of neuronal cell bodies. It is involved in processing and interpreting information and is found in regions like the cortex and deep brain nuclei.\nWhite Matter: Tissue made up of axons coated with myelin, which appears white. White matter connects regions of gray matter, allowing communication across the brain.\nVentricles: Through the middle of the brain filled with cerebrospinal fluid."
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#more-brain-anatomy-and-terminology",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#more-brain-anatomy-and-terminology",
    "title": "Introduction & Data Modalities",
    "section": "More brain anatomy and terminology",
    "text": "More brain anatomy and terminology\n\nCortex: The outer layer of the brain’s gray matter. It is highly folded and responsible for higher cognitive functions like perception, decision-making, and voluntary movement.\nSubcortex: Brain regions located beneath the cortex, including structures like the thalamus, basal ganglia, and hippocampus. These areas are important for functions such as emotion, memory, and movement regulation.\nCerebellum: A separate structure located at the back of the brain, underneath the cortex. It plays a key role in coordinating movement, balance, and fine motor skills."
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#even-more-brain-anatomy-and-terminology",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#even-more-brain-anatomy-and-terminology",
    "title": "Introduction & Data Modalities",
    "section": "Even more brain anatomy and terminology",
    "text": "Even more brain anatomy and terminology\n\nLobes: The brain is divided into four main lobes — frontal, parietal, temporal, and occipital — each associated with specific functions.\nGyri (singular: gyrus): Ridges on the brain’s surface.\nSulci (singular: sulcus): Grooves between the gyri.\nAnterior / Posterior / Superior / Inferior: Anatomical directions — front/back/top/bottom."
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#what-is-an-image",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#what-is-an-image",
    "title": "Introduction & Data Modalities",
    "section": "What is an image?",
    "text": "What is an image?\n\nA function from I(v): \\mathbb{R}^3 \\mapsto \\mathbb{R}.\nNumeric values in the image represent biological values.\nVisually brighter pixels are higher values.\nMRI are collected in the frequency domain, but few people analyze their data there"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#medical-imaging-data-formats",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#medical-imaging-data-formats",
    "title": "Introduction & Data Modalities",
    "section": "Medical imaging data formats",
    "text": "Medical imaging data formats\n\nDICOM: Medical image format, which includes a lot of metadata in the image header. Raw output from MRI scanner. .dcm\nNIfTI: File format for 3D or 4D neuroimaging data with less (but still a lot of) metadata in the image header. .nii or .nii.gz.\n\nYou don’t need to gunzip.nii.gz files, all software can open them directly."
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#neuroimaging-terminology",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#neuroimaging-terminology",
    "title": "Introduction & Data Modalities",
    "section": "Neuroimaging terminology",
    "text": "Neuroimaging terminology\n\nVoxel: A 3D pixel.\nTR: Repetition time - time required to obtain an entire volume (typically for fMRI data).\nTE: Echo time - time between application of a radiofrequency (RF) pulse and the peak of the signal (echo) generated.\nEPI: Echo planar imaging - the type of imaging used to collect fMRI data.\nT1-weighted / T2-weighted images: Types of MRI scans for different tissue properties. T1 show anatomy with good contrast for gray and white matter; T2 highlight fluid and often used to detect pathology."
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#orientation-terminology",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#orientation-terminology",
    "title": "Introduction & Data Modalities",
    "section": "Orientation terminology",
    "text": "Orientation terminology\n\nAxial View: A horizontal slice of the brain, viewed from above (as if looking down from the top of the head).\nCoronal View: A vertical slice viewed from the front (as if looking straight at the face).\nSagittal View: A vertical slice viewed from the side (as if looking at the brain in profile)."
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#image-space",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#image-space",
    "title": "Introduction & Data Modalities",
    "section": "Image space",
    "text": "Image space\n\nintroduction_data_modalities/figures/MNI152_T1_2mm_brain.nii.gz\n\n\nMNI Space / Talairach Space: Standardized brain coordinate systems used to align and compare brain scans across individuals.\nRadiological versus neurological convention\n\nRadiological - (left on the right)\nNeurological - (right on the right)\nNice overview on this stuff\nRadiological is more common"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#atlases",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#atlases",
    "title": "Introduction & Data Modalities",
    "section": "Atlases",
    "text": "Atlases\nAtlases define regions of the brain based on anatomical, microstructural, functional, or other features\n\nCommon Atlases\n\nMNI"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#structural-imaging",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#structural-imaging",
    "title": "Introduction & Data Modalities",
    "section": "Structural imaging",
    "text": "Structural imaging\nMeasures the anatomy of the brain\n\nDerived from T1/T2 MRI scans\nStructural measures\n\nVolume, Cortical thickness, Surface area\n\nData structures\n\nImages\nRegions\nGray matter surface\nStructural-based “similarity” networks"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#freesurfer-structural-analysis-software",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#freesurfer-structural-analysis-software",
    "title": "Introduction & Data Modalities",
    "section": "Freesurfer: structural analysis software",
    "text": "Freesurfer: structural analysis software\n\n\n\nCortical surface estimation and analysis\nNow over 25 years old\nMany tools now built on analyzing data on the surface\n\n\n\n\n\nFischl and Dale 2000"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#freesurfer-visualization",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#freesurfer-visualization",
    "title": "Introduction & Data Modalities",
    "section": "Freesurfer visualization",
    "text": "Freesurfer visualization\n\n\n\n\n\nDiamond et al. 2020\n\n\n\n\n\n\nIrimia et al. 2012"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#functional-imaging",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#functional-imaging",
    "title": "Introduction & Data Modalities",
    "section": "Functional imaging",
    "text": "Functional imaging\nMeasures brain functioning (inferred by deoxygentated blood)\n\n\n\nBlood oxygen level dependent (BOLD) activity\nHistory of functional MRI (Bandettini 2012)\nfunctional Magnetic Resonance Imaging (fMRI) are time-series data\n\n\n\n\n\nEarly fMRI Bandettini 1991"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#types-of-fmri-data",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#types-of-fmri-data",
    "title": "Introduction & Data Modalities",
    "section": "Types of fMRI data",
    "text": "Types of fMRI data\n\ntask fMRI – acquired doing a task\nresting state fMRI (rs-fMRI) – acquired doing nothing"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#task-fmri-overview",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#task-fmri-overview",
    "title": "Introduction & Data Modalities",
    "section": "Task fMRI overview",
    "text": "Task fMRI overview\n\nMeasures brain activity during a task using BOLD signal.\n\nBlock design: repeated task periods alternating with baseline (e.g. 30s task, 30s rest).\nEvent-related design: timing randomized, short stimuli.\nNaturalistic: E.g., viewing a movie.\n\nAnalysis fits a time-series model and compares conditions.\nData structures\n\nImages, Regions, Gray matter surface"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#task-fmri-design-illustrations",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#task-fmri-design-illustrations",
    "title": "Introduction & Data Modalities",
    "section": "Task fMRI design illustrations",
    "text": "Task fMRI design illustrations\n\nBlock versus task designs Petersen & Dubis 2011"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#notes-on-illustration",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#notes-on-illustration",
    "title": "Introduction & Data Modalities",
    "section": "Notes on illustration",
    "text": "Notes on illustration\n\nKnown stimulus time series are convolved with an assumed hemodynamic response function (HRF)\nHRF is well studied, often assumed, and likely inaccurate for many brain regions REFs\nHemodynamic (blood) response to stimuli is slow.\nfMRI sampled every 1.5-3 seconds or so.\nRBC fMRI parameters"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#rbc-task-data",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#rbc-task-data",
    "title": "Introduction & Data Modalities",
    "section": "RBC task data",
    "text": "RBC task data\n\n\n\nWe will analyze Naturalistic viewing data\nNaturalistic viewing of Despicable Me (Furtado 2024)\nDespicable Me clip on Netflix 1:02:09 - 1:12:09\n\n\n\n\n\nDespicable Me"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#rs-fmri",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#rs-fmri",
    "title": "Introduction & Data Modalities",
    "section": "rs-fMRI",
    "text": "rs-fMRI\n\nWhat it is? Correlation between fMRI time-series in the brain at rest (doing nothing).\nHistory: Biswal 1995 first study to do this\nNow, things are quite a bit more sophisticated\nData structures\n\nImages\nRegions\nGray matter surface\nNetworks"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#first-resting-state-networks-de-luca",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#first-resting-state-networks-de-luca",
    "title": "Introduction & Data Modalities",
    "section": "First resting state networks (De Luca)",
    "text": "First resting state networks (De Luca)\nPublished in 2006 using independent components analysis\n\nEarly resting state networks De Luca 2006"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#resting-state-networks-damoiseaux",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#resting-state-networks-damoiseaux",
    "title": "Introduction & Data Modalities",
    "section": "Resting state networks (Damoiseaux)",
    "text": "Resting state networks (Damoiseaux)\nPublished the same year, using a different ICA method.\n\nEarly resting state networks Damoiseaux 2006"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#diffusion-imaging",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#diffusion-imaging",
    "title": "Introduction & Data Modalities",
    "section": "Diffusion imaging",
    "text": "Diffusion imaging\nMeasures features of water “diffusion” in the brain. Typically, to estimate biological features of the white matter\n\nWill not focus on this data type in this course\n\n\nDiffusion imaging in Autism Wilkinson 2016"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#other-measures",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#other-measures",
    "title": "Introduction & Data Modalities",
    "section": "Other measures",
    "text": "Other measures\n\nPerfusion – Quantitative measure of blood flow\nSpectroscopy\nMany others actively in development\nMany “derivatives” exist and in development\n\nDerivatives are quantitative values derived from existing modalities"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#footnotes",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#footnotes",
    "title": "Introduction & Data Modalities",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDirectory paths will be relative to the course directory on Box.↩︎"
  },
  {
    "objectID": "index.html#goals",
    "href": "index.html#goals",
    "title": "Statistical Methods for Neuroimaging",
    "section": "",
    "text": "Goal 1: Provide basic knowledge of neuroimaging so that you (Biostatisticians) can read and understand neuroimaging research.\nGoal 2: Cover modern contributions of biostatistics to neuroimaging methods so you can contribute to novel research in the field."
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "Statistical Methods for Neuroimaging",
    "section": "Description",
    "text": "Description\nThis course covers standard and advanced methods for neuroimage analysis from a biostatistical perspective. Students will learn to analyze and interpret common modalities such as fMRI, structural MRI, cortical thickness, diffusion-weighted imaging, and resting-state connectivity using popular neuroimaging analysis software and visualization tools. Advanced topics may include site/scanner correction, first-level and group-level models, network analysis, AI/machine learning, circularity analysis, multivariate/spatial inference, confidence set methods, and centile methods. Upon completion, students will be prepared to understand and contribute to statistical research in neuroimaging."
  },
  {
    "objectID": "index.html#context",
    "href": "index.html#context",
    "title": "Statistical Methods for Neuroimaging",
    "section": "Context",
    "text": "Context\n\nWho are you (the student): Graduate students with a background in biostatistics or related fields.\nPrerequisites: Prior coursework in statistics or biostatistics and experience with R or Python (I will use R)."
  },
  {
    "objectID": "index.html#links",
    "href": "index.html#links",
    "title": "Statistical Methods for Neuroimaging",
    "section": "Links",
    "text": "Links\n\nBrightspace - For grading and quizzes.\nCourse box directory - For all course materials, including these\nDatasets\nImages used in examples in-class"
  },
  {
    "objectID": "index.html#potential-topics-tentative",
    "href": "index.html#potential-topics-tentative",
    "title": "Statistical Methods for Neuroimaging",
    "section": "Potential Topics (Tentative)",
    "text": "Potential Topics (Tentative)\n\nIntroduction\n\nIntroduction and setup\n\nCourse Introduction\nAccessing repository data, Data Use Agreements (DUA)\nInstalling FSL\n\n\n\n\nData Modalities\n\nIntroduction to Neuroimaging Modalities\n\nfMRI and rs-fMRI Overview\nDTI\nStructural Imaging\n\n\n\n\nPreprocessing and First-Level Analysis\n\nPreprocessing Pipeline\n\nStructural\nfMRI, rs-fMRI\n\nPreprocessing with FSL: Practical Session\nPreprocessing: Brainlife.io/Docker\nFirst-Level Statistical Analysis\n\nfMRI, rs-fMRI Analysis\n\nPractical implementation\n\n\n\nGroup-Level Analysis\n\nMultiplicity, Type 1 error, FWER, FDR\nCluster extent inference, Gaussian field theory, TFCE, Excursion set inference\nFunctional Connectivity: basic group-level analysis\nIn-class activity: implementation in FSL and R\n“Voodoo” correlation\nAdvanced group-level analysis (distance-based)\n\nMDMR, PermANOVA, Semi-parametrics\n\n\n\n\nModern Topics: Reproducibility and Replicability\n\nReproducibility\n\n“The Garden of Forking Paths”\n\nReplicability\n\nSample sizes\nEffect sizes\n\n\n\n\nModern Topics: Machine Learning in Neuroimaging\n\nBrain-behavior associations (e.g. “Multivariate BWAS”)\n\nPrediction\nStatistical inference\n\nReplicability in ML Methods\n\nCircularity, Data Leakage, and Feature Selection\nCross-validation, Bootstrapping\n\nGuest lecture from Megan?\nBrain Age\n\nIn-class activity\n\nOther topics\n\nMVPA\nML methods\nDeep learning\n\n\n\n\nModern Topics: Batch Effects\n\nIllustration with data so far\nComBat\nCovBat\nDeep learning\n\n\n\nModern Topics: Misc\n\nCentile Analysis\nMultimodal Image Analysis"
  },
  {
    "objectID": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html",
    "href": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html",
    "title": "Homework: Despicable Me Preprocessing",
    "section": "",
    "text": "Goal: Effectively implement fMRI preprocessing for the Despicable Me data for a single participant. “Effectively” means choosing reasonable parameters, checking the output from each step, and modifying the approach as needed to get good output.\nInstructions: There are 100 participant folders in the data/RBC/HBN_BIDS/ folder. One is assigned to you in this Google doc where we will put the quality assurance (QA) summaries.\nDeliverables: This document edited to include\n\nCommented code describing each step.\nVisualizations and commentary, as requested specifically, below.\nAll the output from your preprocessing steps included in the participant’s folder on the Box drive.\nQA summaries generated by FSL in the Google doc.\n\nHint: This file is located at 2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.qmd."
  },
  {
    "objectID": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#overview",
    "href": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#overview",
    "title": "Homework: Despicable Me Preprocessing",
    "section": "",
    "text": "Goal: Effectively implement fMRI preprocessing for the Despicable Me data for a single participant. “Effectively” means choosing reasonable parameters, checking the output from each step, and modifying the approach as needed to get good output.\nInstructions: There are 100 participant folders in the data/RBC/HBN_BIDS/ folder. One is assigned to you in this Google doc where we will put the quality assurance (QA) summaries.\nDeliverables: This document edited to include\n\nCommented code describing each step.\nVisualizations and commentary, as requested specifically, below.\nAll the output from your preprocessing steps included in the participant’s folder on the Box drive.\nQA summaries generated by FSL in the Google doc.\n\nHint: This file is located at 2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.qmd."
  },
  {
    "objectID": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#brain-extraction-xx-pts",
    "href": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#brain-extraction-xx-pts",
    "title": "Despicable Me Preprocessing",
    "section": "Brain extraction (XX pts)",
    "text": "Brain extraction (XX pts)\nFor fMRI preprocessing, FSL requires a brain extracted anatomical T1 image. It needs to be with the same name in the same folder as the T1, with the suffix &lt;T1 name&gt;_brain.nii.gz.\n\nUse FSL’s tool to bias correct and then brain extract the T1. If you do not apply bias correction, the brain extraction might look bad.\nFSL’s tool for brain extraction actually doesn’t work too well oftentimes. Create another brain extracted image using the following steps:\n\n\nLinearly register the participants T1 with skull to the MNI 1mm template with skull and save out the transformation matrix.\nInvert the transformation matrix.\nRegister the MNI brain mask to the participant’s T1 image using nearest neighbor interpolation.\nMask the participant’s T1 with the registered brain mask.\n\n\nView both results include a screenshot of the brain extracted image overlaid in semitransparent color or with a boundary on the unextracted (with skull) T1. Use 1-3 sentences to describe why you prefer one method or another.\nFor the method that works better, name that file &lt;T1 name&gt;_brain.nii.gz in the anat folder."
  },
  {
    "objectID": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#field-map",
    "href": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#field-map",
    "title": "Despicable Me Preprocessing",
    "section": "Field map",
    "text": "Field map"
  },
  {
    "objectID": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#slice-timing",
    "href": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#slice-timing",
    "title": "Despicable Me Preprocessing",
    "section": "Slice timing",
    "text": "Slice timing"
  },
  {
    "objectID": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#stimulus-time-series",
    "href": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#stimulus-time-series",
    "title": "Despicable Me Preprocessing",
    "section": "Stimulus time series",
    "text": "Stimulus time series"
  },
  {
    "objectID": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#temporal-filtering",
    "href": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#temporal-filtering",
    "title": "Despicable Me Preprocessing",
    "section": "Temporal filtering",
    "text": "Temporal filtering"
  },
  {
    "objectID": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#motion-correction",
    "href": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#motion-correction",
    "title": "Despicable Me Preprocessing",
    "section": "Motion correction",
    "text": "Motion correction\nPlace motion files in google document\nEach person gets a participant to process with FSL Place registration files in google document"
  },
  {
    "objectID": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#fmri-preprocessing",
    "href": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#fmri-preprocessing",
    "title": "Despicable Me Preprocessing",
    "section": "fMRI preprocessing",
    "text": "fMRI preprocessing\nStart the FSL GUI from the command line by typing fsl and then open the FEAT fMRI Analysis. Set it up to perform preprocessing. If you hover over the options, there is a description that will help you make decisions about the preprocessing parameters throughout.\nHint: On my laptop, when I change the tab in the FEAT GUI, all the buttons go away; if you adjust the window size, they reappear.\nUse these parameters (other parameter settings you will decide for yourself).\n\nSet the output directory to be the folder where the 4D Nifti image is located for that participant.\nSet it to delete 6 volumes.\nUse BBR for “Main structural image” registration.\nTurn on FNIRT for “Standard space” registration and leave the Warp resolution at the default setting.\n\n\nField map (12 pts)\nUse the field map to perform B0 unwarping.\n\n\nSlice timing (6 pts)\nThe slice timing information for the fMRI data are included in the .json file of the same name as the Nifti image in the func folder. Create a slice timing text file to use as input for FSL preprocessing.\n\n\nTemporal filtering (6 pts)\nThe stimulus time series we will use is in the first level model in the data/RBC/stimulusTimeSeries/despicableMe/stickFile.txt file. Choose an appropriate temporal filtering value in FSL based on the stimuli durations.\nExplain here in 1-2 sentences how you decided on your temporal filtering settings."
  },
  {
    "objectID": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#brain-extraction-12-pts",
    "href": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#brain-extraction-12-pts",
    "title": "Homework: Despicable Me Preprocessing",
    "section": "Brain extraction (12 pts)",
    "text": "Brain extraction (12 pts)\nFor fMRI preprocessing, FSL requires a brain extracted anatomical T1 image. It needs to be with the same name in the same folder as the T1, with the suffix &lt;T1 name&gt;_brain.nii.gz.\n\nUse FSL’s tool to bias correct and then brain extract the T1. If you do not apply bias correction, the brain extraction might look bad.\nFSL’s tool for brain extraction actually doesn’t work too well oftentimes. Create another brain extracted image using the following steps:\n\nLinearly register the participants T1 with skull to the MNI 1mm template with skull and save out the transformation matrix.\nInvert the transformation matrix.\nRegister the MNI brain mask to the participant’s T1 image using nearest neighbor interpolation.\nMask the participant’s T1 with the registered brain mask.\n\nInclude a screenshot in this document of both methods of the brain extracted image overlaid in semitransparent color or with a boundary on the unextracted (with skull) T1. Use 1-3 sentences to describe why you prefer one method or another.\nFor the method that works better, name that file &lt;T1 name&gt;_brain.nii.gz in the anat folder to be used for fMRI preprocessing.\nSave all other output in the folder with the T1 image."
  },
  {
    "objectID": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#deliverables-9-pts",
    "href": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#deliverables-9-pts",
    "title": "Homework: Despicable Me Preprocessing",
    "section": "Deliverables (9 pts)",
    "text": "Deliverables (9 pts)\n\nPlace the fMRI to template registration in the Google doc under the “Registration QA” section annotated with the subject ID.\nPlace the motion time series image in the Google doc under the “Motion correction QA” section annotated with the subject ID.\nAll your output, including intermediate steps like the brain extraction intermediate files, should be in the subject’s directories in Box."
  },
  {
    "objectID": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#fmri-preprocessing-24-pts",
    "href": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#fmri-preprocessing-24-pts",
    "title": "Despicable Me Preprocessing",
    "section": "fMRI preprocessing (24 pts)",
    "text": "fMRI preprocessing (24 pts)\nStart the FSL GUI from the command line by typing fsl and then open the FEAT fMRI Analysis. Set it up to perform preprocessing. If you hover over the options, there is a description that will help you make decisions about the preprocessing parameters throughout.\nHint: On my laptop, when I change the tab in the FEAT GUI, all the buttons disappear; if you adjust the window size, they reappear.\nUse these parameters (other parameter settings you will decide for yourself).\n\nSet the output directory to be the folder where the 4D Nifti image is located for that participant.\nSet it to delete 6 volumes.\nUse BBR for “Main structural image” registration.\nTurn on FNIRT for “Standard space” registration and leave the Warp resolution at the default setting.\n\n\nField map (12 pts)\nUse the field map to perform B0 unwarping. You need to do the following:\n\nUse fslmerge to merge the AP and PA Nifti images in the fmap folder.\nDetermine the acquisition parameters from the .json files of the images and write the to a text file.\nRun topup and the remaining commands from the preprocessing page.\n\nThen you will have to select the right FEAT B0 options:\n\nFieldmap image (rad/s)\nEffective EPI echo spacing (ms) - obtained from 4D fMRI data .json file \"TotalReadoutTime\":\nUnwarp direction - obtained from 4D fMRI data .json file \"PhaseEncodingDirection\":\nEPI TE not needed\n\n\n\nSlice timing (6 pts)\nThe slice timing information for the fMRI data are included in the .json file of the same name as the Nifti image in the func folder. Create a slice timing text file to use as input for FSL preprocessing.\n\n\nTemporal filtering (6 pts)\nThe stimulus time series we will use is in the first level model in the data/RBC/stimulusTimeSeries/despicableMe/stickFile.txt file. Choose an appropriate temporal filtering value in FSL based on the stimuli durations.\nExplain here in 1-2 sentences how you decided on your temporal filtering settings."
  },
  {
    "objectID": "2preprocessing/preprocessing.html#distortion-correction-in-fsl",
    "href": "2preprocessing/preprocessing.html#distortion-correction-in-fsl",
    "title": "Preprocessing",
    "section": "Distortion correction in FSL",
    "text": "Distortion correction in FSL\n\n\nCode\ncd data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/fmap\n# merge the two phase encoding images\nfslmerge -t AP_PA_merged.nii.gz sub-NDARAA306NT2_ses-HBNsiteRU_acq-fMRI_dir-AP_epi.nii.gz sub-NDARAA306NT2_ses-HBNsiteRU_acq-fMRI_dir-PA_epi.nii.gz\n# write acquistion parameters x, y, z phase encoding directions. Final parameter is total readout time\necho \"0 -1 0 0.04565\\n0 1 0 0.04565\" &gt; acquisitionParams.txt\n# apply topup\ntopup --imain=AP_PA_merged.nii.gz \\\n--datain=acquisitionParams.txt \\\n--config=b02b0.cnf \\\n--out=topup_AP_PA_b0 \\\n--iout=topup_AP_PA_b0_iout \\\n--fout=topup_AP_PA_b0_fout\n# create mean of two unwarped images\nfslmaths topup_AP_PA_b0_fout.nii.gz -abs -Tmean b0_mean.nii.gz\n# brain extract the mean image\nbet b0_mean.nii.gz b0_mean_brain.nii.gz -m\n# convert Hz to radians\nfslmaths topup_AP_PA_b0_iout.nii.gz -mul 6.283185307179586 field_rads.nii.gz\n\n\nFEAT B0 options:\n\nFieldmap image (rad/s) is field_rads.nii.gz\nMagnitude image is b0_mean_brain.nii.gz\nEffective EPI echo spacing (ms) - obtained from 4D fMRI data .json file \"TotalReadoutTime\": 0.0481411\nUnwarp direction - obtained from 4D fMRI data .json file \"PhaseEncodingDirection\": \"j-\",\nEPI TE not needed"
  },
  {
    "objectID": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#fmri-preprocessing-12-pts",
    "href": "2preprocessing/homework/fMRIpreprocessing/fMRIpreprocessing.html#fmri-preprocessing-12-pts",
    "title": "Homework: Despicable Me Preprocessing",
    "section": "fMRI preprocessing (12 pts)",
    "text": "fMRI preprocessing (12 pts)\nStart the FSL GUI from the command line by typing fsl and then open the FEAT fMRI Analysis. Set it up to perform preprocessing. If you hover over the options, there is a description that will help you make decisions about the preprocessing parameters throughout.\nHint: On my laptop, when I change the tab in the FEAT GUI, all the buttons disappear; if you adjust the window size, they reappear.\nUse these parameters (other parameter settings you will decide for yourself).\n\nSet the output directory to be the folder where the 4D Nifti image is located for that participant.\nSet it to delete 6 volumes.\nUse BBR for “Main structural image” registration.\nTurn on FNIRT for “Standard space” registration and leave the Warp resolution at the default setting.\nLeave B0 unwarping off.\n\n\nSlice timing (6 pts)\nThe slice timing information for the fMRI data are included in the .json file of the same name as the Nifti image in the func folder. Create a slice timing text file to use as input for FSL preprocessing.\n\n\nTemporal filtering (6 pts)\nThe stimulus time series we will use is in the first level model in the data/RBC/stimulusTimeSeries/despicableMe/stickFile.txt file. Choose an appropriate temporal filtering value in FSL based on the stimuli durations.\nExplain here in 1-2 sentences how you decided on your temporal filtering settings."
  },
  {
    "objectID": "2preprocessing/preprocessing.html#distortion-correction-in-fsl-skip-this",
    "href": "2preprocessing/preprocessing.html#distortion-correction-in-fsl-skip-this",
    "title": "Preprocessing",
    "section": "Distortion correction in FSL (skip this)",
    "text": "Distortion correction in FSL (skip this)\n\ncd data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/fmap\n# merge the two phase encoding images\nfslmerge -t AP_PA_merged.nii.gz sub-NDARAA306NT2_ses-HBNsiteRU_acq-fMRI_dir-AP_epi.nii.gz sub-NDARAA306NT2_ses-HBNsiteRU_acq-fMRI_dir-PA_epi.nii.gz\n# write acquistion parameters x, y, z phase encoding directions. Final parameter is total readout time\necho \"0 -1 0 0.04565\\n0 1 0 0.04565\" &gt; acquisitionParams.txt\n# apply topup\ntopup --imain=AP_PA_merged.nii.gz \\\n--datain=acquisitionParams.txt \\\n--config=b02b0.cnf \\\n--out=topup_AP_PA_b0 \\\n--iout=topup_AP_PA_b0_iout \\\n--fout=topup_AP_PA_b0_fout\n# create mean of two unwarped images\nfslmaths topup_AP_PA_b0_fout.nii.gz -abs -Tmean b0_mean.nii.gz\n# brain extract the mean image\nbet b0_mean.nii.gz b0_mean_brain.nii.gz -m\n# convert Hz to radians\nfslmaths topup_AP_PA_b0_iout.nii.gz -mul 6.283185307179586 field_rads.nii.gz\n\nFEAT B0 options:\n\nFieldmap image (rad/s) is field_rads.nii.gz\nMagnitude image is b0_mean_brain.nii.gz\nEffective EPI echo spacing (ms) - obtained from 4D fMRI data .json file \"TotalReadoutTime\": 0.0481411\nUnwarp direction - obtained from 4D fMRI data .json file \"PhaseEncodingDirection\": \"j-\",\nEPI TE not needed"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#asdf",
    "href": "3first-level_analysis/first-level_analysis.html#asdf",
    "title": "First-level Analysis",
    "section": "asdf",
    "text": "asdf\nasdf"
  },
  {
    "objectID": "1introduction_data_modalities/introduction_data_modalities.html#what-is-fmri",
    "href": "1introduction_data_modalities/introduction_data_modalities.html#what-is-fmri",
    "title": "Introduction & Data Modalities",
    "section": "What is fMRI?",
    "text": "What is fMRI?"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#autoregressive-models-and-prewhitening",
    "href": "3first-level_analysis/first-level_analysis.html#autoregressive-models-and-prewhitening",
    "title": "First-level Analysis",
    "section": "Autoregressive models and prewhitening",
    "text": "Autoregressive models and prewhitening\nFILM prewhitening"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#naturalistic-viewing-task-despicable-me",
    "href": "3first-level_analysis/first-level_analysis.html#naturalistic-viewing-task-despicable-me",
    "title": "First-level Analysis",
    "section": "Naturalistic viewing task Despicable Me",
    "text": "Naturalistic viewing task Despicable Me\n\n\n\nWe will analyze Naturalistic viewing data\nNaturalistic viewing of Despicable Me (Furtado 2024)\nDespicable Me clip on Netflix 1:02:09 - 1:12:09\n\n\n\n\n\nDespicable Me"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#important-points",
    "href": "3first-level_analysis/first-level_analysis.html#important-points",
    "title": "First-level Analysis",
    "section": "Important points",
    "text": "Important points\n\ntask fMRI data independent variables (covariates) are determined by task stimulus series\nAnd assume hemodynamic response function (double Gamma HRF)\nModels are fit independently at each voxel (spatial location)\nWe are only talking about fitting models for one participant, right now."
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#time-series-general-linear-models-with-prewhitening",
    "href": "3first-level_analysis/first-level_analysis.html#time-series-general-linear-models-with-prewhitening",
    "title": "First-level Analysis",
    "section": "Time series general linear models with prewhitening",
    "text": "Time series general linear models with prewhitening\n\nNotes here, based on FILM prewhitening\nFor a single voxel v:\n\n\ny(v) = X\\beta(v) + \\varepsilon(v)\n\n\nCan ignore v, since we are applying across all voxels separately\nX \\in \\mathbb{R}^{T \\times p}: Design matrix (task regressors, confounds)\n\\beta \\in \\mathbb{R}^p: Parameter vector\n\\varepsilon \\in \\mathbb{R}^T: Error\nAssumptions: \\mathbb{E}[\\varepsilon] = 0, \\mathrm{Cov}(\\varepsilon ) = V (nonindependent errors)\nIf V treated as proportional to the identity matrix, it will lead to inflated false positive rates (Woolrich et al., 2001)\n\nNaive analysis:\nWhat is the expected value of the least squares estimator? \n\\mathbb{E}(\\hat \\beta) =\n What is the variance of the least squares estimator? \n\\mathrm{Var}(\\hat \\beta) =\n\n\nA naive variance estimator \\hat\\sigma^2 (X^TX)^{-1} will be biased.\n\nStandard errors and test statistics will be biased.\n\nWhat is a solution?"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#general-linear-model-glm-for-fmri",
    "href": "3first-level_analysis/first-level_analysis.html#general-linear-model-glm-for-fmri",
    "title": "First-level Analysis",
    "section": "General Linear Model (GLM) for fMRI",
    "text": "General Linear Model (GLM) for fMRI\n\nFor a single voxel v:\n\n\ny(v) = X\\beta(v) + \\varepsilon(v)\n\n\nX \\in \\mathbb{R}^{T \\times p}: Design matrix (task regressors, confounds)\n\\beta_v \\in \\mathbb{R}^p: Parameter vector\n\\varepsilon_v \\in \\mathbb{R}^T: Error\nAssumptions: \\mathbb{E}[\\varepsilon_v] = 0, \\mathrm{Cov}(\\varepsilon(v) ) = V(v) (nonindependent errors)\nCan ignore v for now, since we are applying across all voxels separately\nIf V treated as proportional to the identity matrix, it wll lead to inflated false positive rates (Woolrich et al., 2001)"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#prewhitening-theory",
    "href": "3first-level_analysis/first-level_analysis.html#prewhitening-theory",
    "title": "First-level Analysis",
    "section": "Prewhitening Theory",
    "text": "Prewhitening Theory\n\nGoal: transform model so residuals are uncorrelated\n\nGiven:\n\ny = X\\beta + \\varepsilon, \\quad \\varepsilon \\sim N(0, V)\n\nLet K be a square root matrix of V such that:\n\nK V K^T = I\n\n\nApply K to both sides:\n\n\nK y = K X \\beta + K \\varepsilon\n\n\nWhat is the marginal distribution of\nThis is prewhitening: transforms correlated errors into white noise\nProblem: V and K are unknown and need to be estimated."
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#film-approach-woolrich-et-al.-2001",
    "href": "3first-level_analysis/first-level_analysis.html#film-approach-woolrich-et-al.-2001",
    "title": "First-level Analysis",
    "section": "FILM Approach (Woolrich et al., 2001)",
    "text": "FILM Approach (Woolrich et al., 2001)\n\nFMRIB’s Improved Linear Model:\nOne-step prewhitening to estimate V\nMany potential time series models to choose from\nFILM models autocorrelation with voxel-wise tapered estimates"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#inference-after-prewhitening",
    "href": "3first-level_analysis/first-level_analysis.html#inference-after-prewhitening",
    "title": "First-level Analysis",
    "section": "Inference After Prewhitening",
    "text": "Inference After Prewhitening\n\nAfter prewhitening, fit OLS:\n\n\n\\hat{\\beta}_v = (X^T K^T K X)^{-1} X^T K^T K y\n\n\nContrast testing:\n\n\nt_v = \\frac{c^\\top \\hat{\\beta}_v}{\\hat{\\sigma}_v \\sqrt{c^\\top (X^\\top K_v^\\top K_v X)^{-1} c}}\n\n\nCorrect inference requires:\n\nCorrect V estimation"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#extensions-and-considerations",
    "href": "3first-level_analysis/first-level_analysis.html#extensions-and-considerations",
    "title": "First-level Analysis",
    "section": "Extensions and Considerations",
    "text": "Extensions and Considerations\n\nAlternative approaches:\n\nNonparametric time series modeling (Eklund et al., 2016)\nPrecoloring (opposite approach to prewhitening)\n\nFILM advantages:\n\nVoxel-wise autocorrelation modeling\nHandles spatial heterogeneity in noise\n\nLimitations:\n\nRequires accurate V_v estimation\nComputationally heavier than simple AR(1) models"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#references",
    "href": "3first-level_analysis/first-level_analysis.html#references",
    "title": "First-level Analysis",
    "section": "References",
    "text": "References\n\nWoolrich MW, Ripley BD, Brady M, Smith SM. (2001) Temporal autocorrelation in univariate linear modeling of fMRI data. NeuroImage, 14(6):1370–1386.\nFriston KJ, et al. (1995) Statistical parametric maps in functional imaging: a general linear approach. Human Brain Mapping, 2(4):189–210."
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#frequency-domain-transformation",
    "href": "3first-level_analysis/first-level_analysis.html#frequency-domain-transformation",
    "title": "First-level Analysis",
    "section": "Frequency domain transformation",
    "text": "Frequency domain transformation"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#stimulus-time-series",
    "href": "3first-level_analysis/first-level_analysis.html#stimulus-time-series",
    "title": "First-level Analysis",
    "section": "Stimulus time series",
    "text": "Stimulus time series\n\nNaturalistic viewing task does not have strict “events” that occur during the task\nSome recent research created continuous emotional ratings for the Despicable Me clip\nWe can use these to define particular “blocks” of particular emotional states during the clip\n\n\ndm = readRDS('../data/RBC/stimulusTimeSeries/despicableMe/emotionBlocks.rds')\nplot(dm$emo_valence, type='p', ylab='Emotional Valence', xlab='Time', main='\"Despicable Me\" emotional ratings',\n     col=as.numeric(dm$positiveBlock) + as.numeric(dm$negativeBlock) -1)"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#complications-with-time-series",
    "href": "3first-level_analysis/first-level_analysis.html#complications-with-time-series",
    "title": "First-level Analysis",
    "section": "Complications with time series",
    "text": "Complications with time series\n\nfMRI time series analysis is more complex than described above\nWhat critical assumption is violated?\n\nWhat will it affect in the model output?\nThink bias and variance of \\hat\\beta and \\hat\\sigma_{\\hat\\beta}^2\n\nUnivariate time series models (such as ARMA) require careful model fit evaluation that is impossible when fitting 150,000 models across the brain"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#input-into-fsl-feat-gui",
    "href": "3first-level_analysis/first-level_analysis.html#input-into-fsl-feat-gui",
    "title": "First-level Analysis",
    "section": "Input into FSL FEAT GUI",
    "text": "Input into FSL FEAT GUI\n\nThe code below creates a file with the stimulus time series needed for FSL’s FEAT GUI\n\n\n# path to fsf file for preprocessing for first participant\n# /Users/vandeks/Library/CloudStorage/Box-Box/SMN/data/RBC/HBN_BIDS/sub-NDARAA306NT2/ses-HBNsiteRU/func/sub-NDARAA306NT2_ses-HBNsiteRU_task-movieDM_bold.feat/design.fsf\nTR = 0.8\npos = rle(dm$positive)\npos$lengths[1] = (pos$lengths[1] - 6)\n# first one starts at zero\npos$starts = c(0, cumsum(pos$lengths)[-length(pos$lengths)]+1)\n# output needed by FSL\nthreeCol = data.frame(onset=pos$starts*TR, duration=pos$lengths*TR, value=pos$values)\nwrite.table(threeCol[threeCol$value==1,], row.name=FALSE, sep=' ', col.names = FALSE, file='../data/RBC/stimulusTimeSeries/despicableMe/positiveStimulus.txt')\n# /Users/vandeks/Library/CloudStorage/Box-Box/SMN/data//RBC/stimulusTimeSeries/despicableMe/positiveStimulus.txt\n\n\nTo input the stimulus time series into FSL, we provide a 3 column text file with the following info\n\nOnset, Duration, Value\n\nInclude temporal derivative and apply temporal filtering.\n\nCreate a similar stimulus time series for the negative emotional blocks"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#general-linear-models-with-prewhitening",
    "href": "3first-level_analysis/first-level_analysis.html#general-linear-models-with-prewhitening",
    "title": "First-level Analysis",
    "section": "General linear models with prewhitening",
    "text": "General linear models with prewhitening\n\nNotes here, based on FILM prewhitening\nFor a single voxel v:\n\n\ny(v) = X\\beta(v) + \\varepsilon(v)\n\n\nCan ignore v, since we are applying across all voxels separately\nX \\in \\mathbb{R}^{T \\times p}: Design matrix (task regressors, confounds)\n\\beta \\in \\mathbb{R}^p: Parameter vector\n\\varepsilon \\in \\mathbb{R}^T: Error\nAssumptions: \\mathbb{E}[\\varepsilon] = 0, \\mathrm{Cov}(\\varepsilon ) = \\sigma^2V (nonindependent errors)\nIf V treated as proportional to the identity matrix, it will lead to inflated false positive rates (Woolrich et al., 2001)\n\nNaive analysis:\nWhat is the expected value of the least squares estimator? \n\\mathbb{E}(\\hat \\beta) =\n What is the variance of the least squares estimator? \n\\mathrm{Var}(\\hat \\beta) =\n\n\nA naive variance estimator \\hat\\sigma^2 (X^TX)^{-1} will be biased.\n\nStandard errors and test statistics will be biased.\n\nWhat is a solution?"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#prewhitening-concept",
    "href": "3first-level_analysis/first-level_analysis.html#prewhitening-concept",
    "title": "First-level Analysis",
    "section": "Prewhitening Concept",
    "text": "Prewhitening Concept\n\nSolution: transform model so residuals are uncorrelated\n\nGiven:\n\ny = X\\beta + \\varepsilon, \\quad \\mathrm{Var}(\\varepsilon) = \\sigma^2V\n\nLet K be a square root matrix of V such that:\n\nK V K^T = I\n\n\nApply K to both sides:\n\n\nK y = K X \\beta + K \\varepsilon\n\n\nWhat is the marginal distribution of Ky?\nThis is prewhitening: transforms correlated errors into “white noise”\nAs you’ve seen, fMRI data are also high-pass filtered to remove low-frequency components.\n\nThe notation in the paper assumes this was already done, resulting in the covariance V\n\nNew Problem: V and K are unknown and need to be estimated."
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#ways-to-estimate-v",
    "href": "3first-level_analysis/first-level_analysis.html#ways-to-estimate-v",
    "title": "First-level Analysis",
    "section": "Ways to estimate V",
    "text": "Ways to estimate V\n\nFor an arbitrary time series x(t) we can compute some estimators of the autocorrelation\nRaw estimator for correlation with lag \\tau\n\n\nr_{xx}(\\tau) = \\frac{1}{\\hat\\sigma} \\sum_{t=1}^{N-\\tau} x(t) x(t+\\tau)/(N-\\tau)\n\n\nTapered estimators, such as the Tukey single-tapering\n\n\n\\hat\\rho_{xx}(\\tau) = \\frac{1}{2}\\left( 1 + \\cos\\left(\\frac{\\pi \\tau}{M}\\right) \\right) r_{xx}(\\tau)\n\nfor \\tau&lt;M and zero otherwise.\n\n\n\n\n\n\nOthers not discussed here (see Woolrich et al., 2001)\nMatrix V can be filled in with these empirical estimators as a Toeplitz matrix\nIf \\beta is known, the formulas are computed with \\epsilon = y - X\\beta\nAlternatively, we could use \\hat\\beta, giving the residuals r = (I- X(X^T X)^{-1} X^T) y\nWhat is the autocorrelation of the residuals?\n\n\n\\mathrm{Cov}(r) =\n\n\nIt is not quite V and V cannot be directly estimated from r. Woolridge et al suggested it is close enough."
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#iterative-procedure-for-prewhitening",
    "href": "3first-level_analysis/first-level_analysis.html#iterative-procedure-for-prewhitening",
    "title": "First-level Analysis",
    "section": "Iterative procedure for prewhitening",
    "text": "Iterative procedure for prewhitening\n\n\\hat\\beta is not the BLUE when the covariance of \\epsilon is V\nThe BLUE is X^T V^{-1} X)^{-1} X^T V^{-1} y (not possible to compute this)\nAfter obtaining estimate for V (and or K), fit OLS:\n\n\n\\hat{\\beta}_1 = (X^T \\hat V^{-1} X)^{-1} X^T \\hat V^{-1} y\n\n\nThen the we could compute a new \\hat V and iterate until convergence.\nThis would take ages across 150,000 voxels, so instead, they just recompute \\hat \\beta_1 once"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#features-of-time-series-data",
    "href": "3first-level_analysis/first-level_analysis.html#features-of-time-series-data",
    "title": "First-level Analysis",
    "section": "Features of time series data",
    "text": "Features of time series data\n\nAuto-correlation\nFrequency domain interpretation"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#new-slide",
    "href": "3first-level_analysis/first-level_analysis.html#new-slide",
    "title": "First-level Analysis",
    "section": "New slide",
    "text": "New slide"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#evaluation",
    "href": "3first-level_analysis/first-level_analysis.html#evaluation",
    "title": "First-level Analysis",
    "section": "Evaluation",
    "text": "Evaluation\n\nContrasts (T- and F-statistics) can be computed:\n\n\nt = \\frac{c^T \\hat{\\beta}}{\\hat{\\sigma} \\sqrt{c^T (X^T \\hat V^{-1} X)^{-1} c}}\n\nand should be approximately normally distributed under the null, in large samples.\n\n\n\nTukey QQ plot with smoothing (MS)"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#frequency-domain-transformations",
    "href": "3first-level_analysis/first-level_analysis.html#frequency-domain-transformations",
    "title": "First-level Analysis",
    "section": "Frequency domain transformations",
    "text": "Frequency domain transformations\n\ne.g. Fourier and Wavelet transformations\nUsed a lot in imaging for spatial and temporal frequency domain transformations\nProcessing and analysis in the frequency domain has a lot of advantages\nI won’t cover it here, as I’m not an expert, but we could come back to it"
  },
  {
    "objectID": "3first-level_analysis/homework/first-level_analysis/first-level_analysis.html",
    "href": "3first-level_analysis/homework/first-level_analysis/first-level_analysis.html",
    "title": "Homework: Despicable Me First-level Analysis",
    "section": "",
    "text": "Goal: Effectively implement fMRI batch first-level analysis for the Despicable Me data for the subset of participants assigned to you. “Effectively” means quality checking intermediate steps.\nInstructions: There are 100 participant folders in the data/RBC/HBN_BIDS/ folder. One is assigned to you in this Google doc where we will put the quality assurance (QA) summaries.\nDeliverables: This document edited to include\n\nCommented code describing each step.\nVisualizations and commentary, as requested specifically, below.\nAll the output from your preprocessing steps included in the participant’s folder on the Box drive.\nQA summaries generated by FSL in the Google doc.\n\nHint: This file is located at 3first-level_analysis/homework/``first-level_analysis``/``first-level_analysis.``qmd."
  },
  {
    "objectID": "3first-level_analysis/homework/first-level_analysis/first-level_analysis.html#overview",
    "href": "3first-level_analysis/homework/first-level_analysis/first-level_analysis.html#overview",
    "title": "Homework: Despicable Me First-level Analysis",
    "section": "",
    "text": "Goal: Effectively implement fMRI batch first-level analysis for the Despicable Me data for the subset of participants assigned to you. “Effectively” means quality checking intermediate steps.\nInstructions: There are 100 participant folders in the data/RBC/HBN_BIDS/ folder. One is assigned to you in this Google doc where we will put the quality assurance (QA) summaries.\nDeliverables: This document edited to include\n\nCommented code describing each step.\nVisualizations and commentary, as requested specifically, below.\nAll the output from your preprocessing steps included in the participant’s folder on the Box drive.\nQA summaries generated by FSL in the Google doc.\n\nHint: This file is located at 3first-level_analysis/homework/``first-level_analysis``/``first-level_analysis.``qmd."
  },
  {
    "objectID": "3first-level_analysis/homework/first-level_analysis/first-level_analysis.html#batch-brain-extraction-20-pts",
    "href": "3first-level_analysis/homework/first-level_analysis/first-level_analysis.html#batch-brain-extraction-20-pts",
    "title": "Homework: Despicable Me First-level Analysis",
    "section": "Batch brain extraction (20 pts)",
    "text": "Batch brain extraction (20 pts)\nAfter our last class, we should have found one of two brain extraction methods that worked well for these data and decided as a class (if not, yet, remind Simon about that we need to do this). Run bias correction and brain extraction on your full subset of images to get the output you need as input for FEAT. You can work in your group or as a class to write a batch script, or you can share code to do this.\nWrite a loop in R in this document to create a visualization of one or a couple slices for each participant to quality check the brain extraction and add it to this document to be submitted as an html."
  },
  {
    "objectID": "3first-level_analysis/homework/first-level_analysis/first-level_analysis.html#fmri-first-level-analysis-30-pts",
    "href": "3first-level_analysis/homework/first-level_analysis/first-level_analysis.html#fmri-first-level-analysis-30-pts",
    "title": "Homework: Despicable Me First-level Analysis",
    "section": "fMRI first-level analysis (30 pts)",
    "text": "fMRI first-level analysis (30 pts)\nStart the FSL GUI from the command line by typing fsl and then open the FEAT fMRI Analysis (can also do this directly typing Feat_gui at the command line. Open the .fsf file you produced from your last homework and set it up to perform the statistical analysis for the Despicable Me data. All the prior settings you used before loaded in.\nHint: On my laptop, when I change the tab in the FEAT GUI, all the buttons disappear; if you adjust the window size, they reappear.\nDo these things:\n\nSet the temporal filtering high-pass filtering to 130 seconds.\nMake sure you have the right slice timing file. This should be the same for all participants you are analyzing.\nSelect all 4D Nifti images for the subset of participants you are analyzing.\nSelect all brain-extracted structural images for the subset of participants you are analyzing. Hint: They have to be in the same order as the 4D fMRI images.\nConstruct two events, include the temporal derivative and apply temporal filtering to the event file. Use the double gamma HRF.\n\nPositive valence emotions\nNegative valence emotions\n\nConstruct three contrasts\n\nPositive valence emotions (versus baseline/unmodeled)\nNegative valence emotions (versus baseline/unmodeled)\nPositive minus negative emotions\n\n\nInclude a screenshot of your design in here, in your html submission.\nRun the analysis. Hint: You might want to run it for one person and check the output. Then run it for everyone in your subset and run it overnight."
  },
  {
    "objectID": "3first-level_analysis/homework/first-level_analysis/first-level_analysis.html#deliverables-xx-pts",
    "href": "3first-level_analysis/homework/first-level_analysis/first-level_analysis.html#deliverables-xx-pts",
    "title": "Homework: Despicable Me First-level Analysis",
    "section": "Deliverables (XX pts)",
    "text": "Deliverables (XX pts)\n\nPlace the fMRI to template registration in the Google doc under the “Registration QA” section annotated with the subject ID.\nPlace the motion time series image in the Google doc under the “Motion correction QA” section annotated with the subject ID.\nAll your output, including intermediate steps like the brain extraction intermediate files, should be in the subject’s directories in Box."
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#assigning-participants-to-students",
    "href": "3first-level_analysis/first-level_analysis.html#assigning-participants-to-students",
    "title": "First-level Analysis",
    "section": "Assigning participants to students",
    "text": "Assigning participants to students\n\nSites have different scan parameters, which means we need to process the data differently for each site\nHere, we’ll assign each of you a chunk of participants to process from the same site\n(More on site harmonization later)\n\n\nsites = read.table(file = '../data/RBC/sites.txt', sep = '/', header = FALSE, col.names=c('subject', 'site'))\ntable(sites$site)"
  },
  {
    "objectID": "3first-level_analysis/homework/first-level_analysis/first-level_analysis.html#deliverables-10-pts",
    "href": "3first-level_analysis/homework/first-level_analysis/first-level_analysis.html#deliverables-10-pts",
    "title": "Homework: Despicable Me First-level Analysis",
    "section": "Deliverables (10 pts)",
    "text": "Deliverables (10 pts)\n\nRegistration QA\n\nWrite a loop or lapply command to print all the functional-to-standard registration images (“Registration of example_func to standard”) into this document. Include the subject ID in the output so you can identify who they belong to. Hint: They are stored in the participants .feat folder output in the mc folder and you can print from loops using results-'asis' and cat to print the markdown syntax you need.\nCreate a list of participants whose registration is bad that we might exclude from analysis.\n\n\n\nMotion QA\n\nWrite a loop or lapply command to print all the motion plots (“MCFLIRT estimated mean displacement (mm)”) into this document. Include the subject ID in the output so you can identify who they belong to. Hint: They are stored in the participants .feat folder output in the mc folder and you can print from loops using results-'asis' and cat to print the markdown syntax you need.\nCreate a list of participants whose mean relative displacement is larger than 0.5mm. We will exclude those participants from the analyses."
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#design-setup",
    "href": "3first-level_analysis/first-level_analysis.html#design-setup",
    "title": "First-level Analysis",
    "section": "Design setup",
    "text": "Design setup\n\nDesign matrix"
  },
  {
    "objectID": "4group-level_analysis/group-level_analysis.html#overview",
    "href": "4group-level_analysis/group-level_analysis.html#overview",
    "title": "Group-level Analysis",
    "section": "Overview",
    "text": "Overview\n\nGroup-level analysis refers to analyses that seek to model associations between nonimaging individual differences with measures of the brain derived from MRI (or another imaging modality)\nFor univariate data, this often would correspond to a mixed model or other multi-level analysis model\nBecause of computational demand, in Neuroimaging these are fit in multiple stages"
  },
  {
    "objectID": "4group-level_analysis/group-level_analysis.html#section-outline",
    "href": "4group-level_analysis/group-level_analysis.html#section-outline",
    "title": "Group-level Analysis",
    "section": "Section outline",
    "text": "Section outline\n\nModeling and estimation\nStatistical inference"
  },
  {
    "objectID": "4group-level_analysis/group-level_analysis.html#why-are-neuroimaging-data-multilevel",
    "href": "4group-level_analysis/group-level_analysis.html#why-are-neuroimaging-data-multilevel",
    "title": "Group-level Analysis",
    "section": "Why are neuroimaging data multilevel?",
    "text": "Why are neuroimaging data multilevel?\n\nIntroduces two challenges\n\nCorrelation among measurements\nHeteroskedasticity (variance differs between participants)"
  },
  {
    "objectID": "4group-level_analysis/group-level_analysis.html#example-group-differences-in",
    "href": "4group-level_analysis/group-level_analysis.html#example-group-differences-in",
    "title": "Group-level Analysis",
    "section": "Example: Group differences in",
    "text": "Example: Group differences in"
  },
  {
    "objectID": "4group-level_analysis/group-level_analysis.html#multiple-measurements-on-the-same-participant",
    "href": "4group-level_analysis/group-level_analysis.html#multiple-measurements-on-the-same-participant",
    "title": "Group-level Analysis",
    "section": "Multiple measurements on the same participant",
    "text": "Multiple measurements on the same participant"
  },
  {
    "objectID": "4group-level_analysis/group-level_analysis.html#random-effects-analysis",
    "href": "4group-level_analysis/group-level_analysis.html#random-effects-analysis",
    "title": "Group-level Analysis",
    "section": "Random effects analysis",
    "text": "Random effects analysis"
  },
  {
    "objectID": "4group-level_analysis/group-level_analysis.html#heteroskedasticity",
    "href": "4group-level_analysis/group-level_analysis.html#heteroskedasticity",
    "title": "Group-level Analysis",
    "section": "Heteroskedasticity",
    "text": "Heteroskedasticity"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#temporal-high-pass-filtering",
    "href": "2preprocessing/preprocessing.html#temporal-high-pass-filtering",
    "title": "Preprocessing",
    "section": "Temporal (high-pass) filtering",
    "text": "Temporal (high-pass) filtering\n\nOccurs as part of the first-level analysis to remove low-frequency drift\nUses a discrete cosine transform on the time series and uses them as covariates in a regression (first-level analysis)"
  },
  {
    "objectID": "2preprocessing/preprocessing.html#implementation-in-fsl",
    "href": "2preprocessing/preprocessing.html#implementation-in-fsl",
    "title": "Preprocessing",
    "section": "Implementation in FSL",
    "text": "Implementation in FSL\n\nThe cutoff in FSL’s high-pass filter (implemented via DCT regressors) is chosen based on the longest period of signal variation you want to keep relative to your task design.\n\nHow the DCT cutoff works\n\nFEAT asks you for a high-pass filter cutoff (in seconds), e.g. 100s.\nThis is the minimum period length that will be modeled as noise.\n\nAll fluctuations slower than this period (i.e., longer trends) are captured by the DCT regressors and removed.\nFaster fluctuations (shorter than this period) remain in the data/GLM.\nImplementation: a set of cosine basis functions with periods ≥ cutoff are generated, spaced to cover the run length.\nRule of thumb in FSL: 2 × the longest inter-stimulus interval (ISI) / block length in your design.\nSimon: Needs to be longer than the longest block length\nRationale: you want to preserve your task regressors of interest, but still remove very slow scanner drift.\n\nTypical defaults:\n\nPerfect — let’s dig into the math of how FSL implements the high-pass filter cutoff with DCT regressors."
  },
  {
    "objectID": "2preprocessing/preprocessing.html#notes-from-chatgpt-about-dct-ii-used-in-fsl",
    "href": "2preprocessing/preprocessing.html#notes-from-chatgpt-about-dct-ii-used-in-fsl",
    "title": "Preprocessing",
    "section": "Notes from ChatGPT about DCT-II used in FSL",
    "text": "Notes from ChatGPT about DCT-II used in FSL\nFSL uses a Discrete Cosine Transform (DCT, Type II) basis set to model slow drifts.\nIf you have a run of length T seconds (N volumes × TR), then for each time point t = 0, 1, \\dots, N-1:\n\nX_{k}(t) \\;=\\; \\cos\\!\\Bigg( \\frac{\\pi (t+0.5)k}{N} \\Bigg), \\quad k=0,1,\\dots,N-1\n\nThis is the standard DCT-II form. Each k corresponds to a different frequency (periodicity)."
  },
  {
    "objectID": "2preprocessing/preprocessing.html#implementation-in-feat",
    "href": "2preprocessing/preprocessing.html#implementation-in-feat",
    "title": "Preprocessing",
    "section": "3. Implementation in FEAT",
    "text": "3. Implementation in FEAT\n\nFEAT computes how many DCT terms are needed so that the lowest frequency kept matches the cutoff.\nExample: run length T=600 s (10 min).\n\nWith TR=2 s, N=300.\nPeriod for k=1: P_1 = 2T/1 = 1200 s.\nPeriod for k=6: P_6 = 200 s.\nPeriod for k=12: P_{12} = 100 s.\nSo for cutoff=100 s, FEAT will include regressors up through k=12.\n\n\nThis way, any oscillation longer than 100 s is modeled by the DCT regressors and removed.\n\nCutoff = 100 s → all trends slower than 0.01 Hz are treated as nuisance.\nThe DCT-II regressors are simply orthogonal cosines spanning these low frequencies.\nThey’re included in the design matrix, so FILM estimates and removes them along with the task regressors."
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#recap-of-task-fmri-processing",
    "href": "3first-level_analysis/first-level_analysis.html#recap-of-task-fmri-processing",
    "title": "First-level Analysis",
    "section": "Recap of task fMRI processing",
    "text": "Recap of task fMRI processing\n\nInhomogeneity correction\nBrain extraction (via structural image)\nRegistration\nMotion correction\nSlice timing correction\nDistortion correction (if field map available)\nTemporal filtering & confound regression\nSpatial smoothing"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#rs-fmri-unique-processing",
    "href": "3first-level_analysis/first-level_analysis.html#rs-fmri-unique-processing",
    "title": "First-level Analysis",
    "section": "rs-fMRI unique processing",
    "text": "rs-fMRI unique processing\n\nrs-fMRI is highly sensitive to motion artifact and noise\nMore aggressive preprocessing steps:\n\nScrubbing – removing/modeling out high-motion time points\nIntensive nuisance covariate removal (24 parameters)\nBand-pass filtering (removing high frequency components as well)\nIndependent Components Analysis (ICA) denoising – potential alternative to regression\n\n\nReferences Ciric et al., 2017 Parkes et al. 2018"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#band-pass-filtering",
    "href": "3first-level_analysis/first-level_analysis.html#band-pass-filtering",
    "title": "First-level Analysis",
    "section": "Band-pass filtering",
    "text": "Band-pass filtering\n\nSimilar, but keeping only frequencies in a range\nPerformed at the same time as nuisance regression"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#nuisance-regression",
    "href": "3first-level_analysis/first-level_analysis.html#nuisance-regression",
    "title": "First-level Analysis",
    "section": "Nuisance regression",
    "text": "Nuisance regression\n\nMotion –\naCompCor – regress out white matter and CSF signals\n\nMeans?\nWhat is aCompCor?"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#scrubbing",
    "href": "3first-level_analysis/first-level_analysis.html#scrubbing",
    "title": "First-level Analysis",
    "section": "Scrubbing",
    "text": "Scrubbing\n“Dummy”/“One hot” coding of scans where participant move a lot\nIn the end, the preprocessing regression design matrix for rs-fMRI might look something like\n\n\\begin{bmatrix}\n\\vert & \\vert & \\vert& \\vert \\\\\n\\text{Temp filt} & \\text{Motion} & \\text{aCompCor} & \\text{Dummy variables} \\\\\n\\vert & \\vert & \\vert & \\vert\n\\end{bmatrix}"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#references-1",
    "href": "3first-level_analysis/first-level_analysis.html#references-1",
    "title": "First-level Analysis",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#nuisance-regression-related-to-motion",
    "href": "3first-level_analysis/first-level_analysis.html#nuisance-regression-related-to-motion",
    "title": "First-level Analysis",
    "section": "Nuisance regression (related to motion)",
    "text": "Nuisance regression (related to motion)\n\nMotion – 24 parameters total\n\nTranslation and rotation – 6 total parameters\nDerivatives – 6 more\nSquares of translation and rotations\nSquares of derivatives"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#nuisance-regression-nuisance-signal",
    "href": "3first-level_analysis/first-level_analysis.html#nuisance-regression-nuisance-signal",
    "title": "First-level Analysis",
    "section": "Nuisance regression (nuisance signal)",
    "text": "Nuisance regression (nuisance signal)\naCompCor – Anatomical Component Correlation\n\nIn addition to motion covariates\nCSF and white matter are not “active” – regress out signal associated with these\nPCA of the signal in these regions, e.g. \nY_{\\mathrm{CSF}} \\in \\mathbb{R}^{T \\times V_{\\mathrm{CSF} }} \\\\\nY_{\\mathrm{CSF}} = U D W^T\n Choose the first K components and regress them out of the data"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#global-signal-regression",
    "href": "3first-level_analysis/first-level_analysis.html#global-signal-regression",
    "title": "First-level Analysis",
    "section": "Global signal regression",
    "text": "Global signal regression\n\nControversial because there is evidence it increases motion-related correlations between distant brain regions\nI am not too familiar why, could be a good advanced topic\nREFs."
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#rs-fmri-before-and-after-preprocessing",
    "href": "3first-level_analysis/first-level_analysis.html#rs-fmri-before-and-after-preprocessing",
    "title": "First-level Analysis",
    "section": "rs-fMRI before and after preprocessing",
    "text": "rs-fMRI before and after preprocessing\n\nHistogram of signal changes\nPositive/negative correlations are relative to preprocessing\n\n\nWhitfield-Gabrieli 2012"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#rs-fmri-first-level-analysis",
    "href": "3first-level_analysis/first-level_analysis.html#rs-fmri-first-level-analysis",
    "title": "First-level Analysis",
    "section": "rs-fMRI first-level analysis",
    "text": "rs-fMRI first-level analysis\n\nPretty straightforward after preprocessing\nFunctional connectivity is defined as Pearson correlation between two locations (R(v,t) is the residuals from the preprocessing)\n\n\n\\hat \\rho(v,w) = \\frac{\\sum_{t=1}^T R(v, t) R(w, t)}{\\sqrt{\\sum_{t=1}^T R(v, t) ^2 \\times \\sum_{t=1}^T R(w, t)^2  } }\n * Correlations are Fisher Z-transformed so that they are approximately normal\n\nZ(v,w) = \\mathrm{atanh}(\\hat \\rho(v,w))\n\n\nTypes of analyses\n\nNetwork – all voxel-to-voxel or region-to-region correlations\nSeed-based – Correlation of preselected seed region with entire image (image-valued)"
  },
  {
    "objectID": "3first-level_analysis/first-level_analysis.html#overview-of-rs-fmri",
    "href": "3first-level_analysis/first-level_analysis.html#overview-of-rs-fmri",
    "title": "First-level Analysis",
    "section": "Overview of rs-fMRI",
    "text": "Overview of rs-fMRI\n\n\nWhitfield-Gabrieli 2012"
  }
]